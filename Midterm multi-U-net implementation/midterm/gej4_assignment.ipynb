{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zsoo02FeKndK"
   },
   "source": [
    "# Midterm\n",
    "\n",
    "The midterm project will consist of a comparison between several CNN architectures for prostate segmentation. The goal is both to create a high-performing algorithm for the target task, as well as to analyze performance across several different architecture permutations. In total, three different network designs will be tested. As each model is built and trained, ensure to serialize the final model `*.hdf5` file before moving to the next iteration.\n",
    "\n",
    "This assignment is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m7WxFT-zKndO"
   },
   "source": [
    "### Submission\n",
    "\n",
    "Once complete, the following items must be submitted:\n",
    "\n",
    "* final `*.ipynb` notebook\n",
    "* final trained `*.hdf5` model files for all three models\n",
    "* final compiled `*.csv` file with performance statistics across the different architectures\n",
    "* final 1-page write-up with methods and results of experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56d3oMiMw8Wm"
   },
   "source": [
    "# Google Colab\n",
    "\n",
    "The following lines of code will configure your Google Colab environment for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R0vrcOpxKndW"
   },
   "source": [
    "### Enable GPU runtime\n",
    "\n",
    "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
    "\n",
    "```\n",
    "Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z2wui0xtKndY"
   },
   "source": [
    "### Mount Google Drive\n",
    "\n",
    "The Google Colab environment is transient and will reset after any prolonged break in activity. To retain important and/or large files between sessions, use the following lines of code to mount your personal Google drive to this Colab instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "UNpUEy0kKndb",
    "outputId": "da0a3c47-dc59-42c2-8430-4afb65fd1eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # --- Mount gdrive to /content/drive/My Drive/\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0CL0p7PhKndo"
   },
   "source": [
    "Throughout this assignment we will use the following global `MOUNT_ROOT` variable to reference a location to store long-term data. If you are using a local Jupyter server and/or wish to store your data elsewhere, please update this variable now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4H4HCiPKndq"
   },
   "outputs": [],
   "source": [
    "# --- Set data directory\n",
    "MOUNT_ROOT = '/content/drive/My Drive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KXySH4NyKnd4"
   },
   "source": [
    "### Select Tensorflow library version\n",
    "\n",
    "This assignment will use the (new) Tensorflow 2.0 library. Use the following line of code to select this updated version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRNh_CubKnd6"
   },
   "outputs": [],
   "source": [
    "# --- Select Tensorflow 2.0 (only in Google Colab)\n",
    "% tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2u5dFZisKneB"
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYKAqEhMKneC"
   },
   "source": [
    "### Jarvis library\n",
    "\n",
    "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "A0knvCWHKneE",
    "outputId": "e2ef8aff-9c87-4b56-bee2-1d498c1ce90e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jarvis-md\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/de/f5d39bfb27c0af58de808a5ee4da4d1c883444c1c6d4b4c53df89ad9612e/jarvis_md-0.0.1a6-py3-none-any.whl (59kB)\n",
      "\r",
      "\u001b[K     |█████▌                          | 10kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 20kB 2.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 30kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 40kB 2.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 51kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 61kB 1.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.23.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.10.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.0.3)\n",
      "Collecting pyyaml>=5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "\u001b[K     |████████████████████████████████| 276kB 6.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.18.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (3.2.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2.9)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->jarvis-md) (1.12.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->jarvis-md) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->jarvis-md) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (2.4.7)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=225546d1c05f1dc0b71da62e5727893b37370146def13afddac56e15f0f2a51b\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, jarvis-md\n",
      "  Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed jarvis-md-0.0.1a6 pyyaml-5.3.1\n"
     ]
    }
   ],
   "source": [
    "# --- Install jarvis (only in Google Colab or local runtime)\n",
    "% pip install jarvis-md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Iw4GmoCKneK"
   },
   "source": [
    "### Imports\n",
    "\n",
    "Use the following lines to import any additional needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EU6ySL08KneL"
   },
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "from tensorflow import losses, optimizers\n",
    "from tensorflow.keras import Input, Model, models, layers\n",
    "from jarvis.train import datasets, custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rDMmb5hHKneS"
   },
   "source": [
    "# Data\n",
    "\n",
    "As in the tutorial, data for this assignment will consist of prostate MRI exams. In prior work, an algorithm was created to separate out different MRI sequences. In this current assignment, only T2-weighted images (isolated using the prior algorithm) will be used for segmentation. In prostate imaging, the T2-weighted sequence captures the greatest amount of anatomic detail and is thus ideal for delineation of prostate gland structures.\n",
    "\n",
    "The following lines of code will download the dataset (if not already present). Since each algorithm below requires a different dataset, the required generators and inputs will be defined dyanically in the code blocks later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Y5aF8OJLKneT",
    "outputId": "0f655a76-699d-4e13-f7c1-ba879220233d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-13 10:47:25 ] [====================] 100.000% : Extracting archive (0001380 / 0001380) "
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'code': '/data/raw/mr_prostatex_seg', 'data': '/data/raw/mr_prostatex_seg'}"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Download dataset\n",
    "datasets.download(name='mr/prostatex-seg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Go01TnHUKneY"
   },
   "source": [
    "# Training\n",
    "\n",
    "A total of three different network architectures will be tested. The goal is to compare the incremental benefit of several design choices. After building and training each model to convergence, do not forget to save each model as a separate `*.hdf5` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_2d7LITKneZ"
   },
   "source": [
    "## 1. 2D U-Net (single step)\n",
    "\n",
    "In this algorithm a standard 2D U-Net architecture will be used to perform prostate segmentation. This network is **identical** to the week 5 assignment. The algorithm input will include an entire full field-of-view `256 x 256` resolution 2D slice from a T2 weighted MR image. Key customizations to the standard U-Net architecture that should be implemented (as in the week 5 assignment) include:\n",
    "\n",
    "* same padding (vs. valid padding)\n",
    "* strided convolutions (vs. max-pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9l_Yc4-rKnea"
   },
   "source": [
    "### Create generators and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Ke0LwfRKnea"
   },
   "outputs": [],
   "source": [
    "# --- Original 256 x 256 (one-step)\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/prostatex-seg', keyword='seg-256')\n",
    "inputs = client.get_inputs(Input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eqea-Ki0Kned"
   },
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "75U4D4SccCMv"
   },
   "outputs": [],
   "source": [
    "# --- Define kwargs\n",
    "kwargs = {\n",
    "    'kernel_size': (1, 3, 3),\n",
    "    'padding': 'same',\n",
    "    'kernel_initializer': 'he_normal'}\n",
    "\n",
    "# --- Define block components\n",
    "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
    "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
    "\n",
    "norm = lambda x : layers.BatchNormalization()(x)\n",
    "relu = lambda x : layers.LeakyReLU()(x)\n",
    "\n",
    "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 1, 1))))\n",
    "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))\n",
    "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=(1, 2, 2))))\n",
    "\n",
    "concat = lambda a, b : layers.Concatenate()([a, b])\n",
    "\n",
    "# --- Define model\n",
    "l1 = conv1(8, inputs['dat'])\n",
    "l2 = conv1(16, conv2(16, l1))\n",
    "l3 = conv1(32, conv2(32, l2))\n",
    "l4 = conv1(48, conv2(48, l3))\n",
    "l5 = conv1(64, conv2(64, l4))\n",
    "l6 = tran2(48, l5)\n",
    "l7 = tran2(32, conv1(48, concat(l4, l6)))\n",
    "l8 = tran2(16, conv1(32, concat(l3, l7)))\n",
    "l9 = tran2(8, conv1(16, concat(l2, l8)))\n",
    "l10 = conv1(8, l9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3a5fxVUbKnee"
   },
   "outputs": [],
   "source": [
    "# --- Create logits\n",
    "logits = {}\n",
    "logits['zones'] = layers.Conv3D(filters=3, name='zones', **kwargs)(l10)\n",
    "\n",
    "# --- Create model\n",
    "model = Model(inputs=inputs, outputs=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QDiWHdWKnei"
   },
   "source": [
    "### Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "id": "JZzr2yhfKnej",
    "outputId": "159d7620-78cd-469c-b96e-e5ebc4a4801b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-13 10:47:46 ] [====================] 100.000% : Iterating | 000342    WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "Epoch 1/12\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "500/500 [==============================] - 128s 256ms/step - loss: 0.4110 - dsc_1: 0.5347 - dsc_2: 0.0125\n",
      "Epoch 2/12\n",
      "500/500 [==============================] - 128s 257ms/step - loss: 0.0671 - dsc_1: 0.7525 - dsc_2: 0.0482\n",
      "Epoch 3/12\n",
      "500/500 [==============================] - 129s 258ms/step - loss: 0.0375 - dsc_1: 0.8212 - dsc_2: 0.4682\n",
      "Epoch 4/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0275 - dsc_1: 0.8589 - dsc_2: 0.6298WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "500/500 [==============================] - 164s 329ms/step - loss: 0.0275 - dsc_1: 0.8589 - dsc_2: 0.6298 - val_loss: 0.0284 - val_dsc_1: 0.8448 - val_dsc_2: 0.6151\n",
      "Epoch 5/12\n",
      "500/500 [==============================] - 128s 257ms/step - loss: 0.0230 - dsc_1: 0.8727 - dsc_2: 0.6676\n",
      "Epoch 6/12\n",
      "500/500 [==============================] - 128s 256ms/step - loss: 0.0206 - dsc_1: 0.8785 - dsc_2: 0.6837\n",
      "Epoch 7/12\n",
      "500/500 [==============================] - 128s 256ms/step - loss: 0.0187 - dsc_1: 0.8891 - dsc_2: 0.7013\n",
      "Epoch 8/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0173 - dsc_1: 0.8922 - dsc_2: 0.7140WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "500/500 [==============================] - 163s 325ms/step - loss: 0.0173 - dsc_1: 0.8922 - dsc_2: 0.7140 - val_loss: 0.0200 - val_dsc_1: 0.8877 - val_dsc_2: 0.7006\n",
      "Epoch 9/12\n",
      "500/500 [==============================] - 128s 256ms/step - loss: 0.0165 - dsc_1: 0.8977 - dsc_2: 0.7235\n",
      "Epoch 10/12\n",
      "500/500 [==============================] - 128s 256ms/step - loss: 0.0157 - dsc_1: 0.9018 - dsc_2: 0.7311\n",
      "Epoch 11/12\n",
      "500/500 [==============================] - 128s 256ms/step - loss: 0.0153 - dsc_1: 0.9045 - dsc_2: 0.7407\n",
      "Epoch 12/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0146 - dsc_1: 0.9057 - dsc_2: 0.7467WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "500/500 [==============================] - 163s 326ms/step - loss: 0.0146 - dsc_1: 0.9057 - dsc_2: 0.7467 - val_loss: 0.0185 - val_dsc_1: 0.8969 - val_dsc_2: 0.7020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1f14855f28>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Compile model\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
    "    loss={'zones': losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
    "    metrics={'zones': custom.dsc(cls=2)},\n",
    "    experimental_run_tf_function=False)\n",
    "\n",
    "# --- Load data into memory for faster training\n",
    "client.load_data_in_memory()\n",
    "\n",
    "# --- Train the model\n",
    "model.fit(\n",
    "    x=gen_train, \n",
    "    steps_per_epoch=500, \n",
    "    epochs=12,\n",
    "    validation_data=gen_valid,\n",
    "    validation_steps=500,\n",
    "    validation_freq=4,\n",
    "    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uiRVFrnKnen"
   },
   "source": [
    "## 2. 2D U-Net (multiple step)\n",
    "\n",
    "In this algorithm, the output of the first 2D U-Net will be used to generated a cropped `128 x 128` resolution 2D slice centered around the prostate gland. This method effectively focuses the algorithm field-of-view to the area of interest and helps improve on inherent class imbalance associated with this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GaFUB_1yKnen"
   },
   "source": [
    "### Create generators and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XTQsQp3fKneo"
   },
   "outputs": [],
   "source": [
    "# --- Cropped 128 x 128 (multiple step)\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/prostatex-seg', keyword='seg-crp')\n",
    "inputs = client.get_inputs(Input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAi6DA9vKnes"
   },
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KpPAwHw9Knet"
   },
   "outputs": [],
   "source": [
    "# --- Define model\n",
    "l1 = conv1(8, inputs['dat'])\n",
    "l2 = conv1(16, conv2(16, l1))\n",
    "l3 = conv1(32, conv2(32, l2))\n",
    "l4 = conv1(48, conv2(48, l3))\n",
    "l5 = conv1(64, conv2(64, l4))\n",
    "l6 = tran2(48, l5)\n",
    "l7 = tran2(32, conv1(48, concat(l4, l6)))\n",
    "l8 = tran2(16, conv1(32, concat(l3, l7)))\n",
    "l9 = tran2(8, conv1(16, concat(l2, l8)))\n",
    "l10 = conv1(8, l9)\n",
    "\n",
    "# --- Create logits\n",
    "logits_128 = {}\n",
    "logits_128['zones'] = layers.Conv3D(filters=3, name='zones', **kwargs)(l10)\n",
    "\n",
    "# --- Create model\n",
    "model_128= Model(inputs=inputs, outputs=logits_128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CACxLXPaKnex"
   },
   "source": [
    "### Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "id": "q0VF6bvSKney",
    "outputId": "9f7be075-cfe9-4099-947b-fe6d55f69502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-13 11:15:32 ] [====================] 100.000% : Iterating | 000342    WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "Epoch 1/12\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.3832 - dsc_1: 0.6823 - dsc_2: 0.3448\n",
      "Epoch 2/12\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.1464 - dsc_1: 0.8508 - dsc_2: 0.6536\n",
      "Epoch 3/12\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.1164 - dsc_1: 0.8753 - dsc_2: 0.6988\n",
      "Epoch 4/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1056 - dsc_1: 0.8840 - dsc_2: 0.7236WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "500/500 [==============================] - 54s 108ms/step - loss: 0.1056 - dsc_1: 0.8840 - dsc_2: 0.7236 - val_loss: 0.1050 - val_dsc_1: 0.8820 - val_dsc_2: 0.7045\n",
      "Epoch 5/12\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.0992 - dsc_1: 0.8899 - dsc_2: 0.7327\n",
      "Epoch 6/12\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.0923 - dsc_1: 0.8997 - dsc_2: 0.7491\n",
      "Epoch 7/12\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.0874 - dsc_1: 0.9034 - dsc_2: 0.7575\n",
      "Epoch 8/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0851 - dsc_1: 0.9034 - dsc_2: 0.7624WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "500/500 [==============================] - 54s 108ms/step - loss: 0.0851 - dsc_1: 0.9034 - dsc_2: 0.7624 - val_loss: 0.1017 - val_dsc_1: 0.8939 - val_dsc_2: 0.6891\n",
      "Epoch 9/12\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.0817 - dsc_1: 0.9103 - dsc_2: 0.7705\n",
      "Epoch 10/12\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.0787 - dsc_1: 0.9119 - dsc_2: 0.7794\n",
      "Epoch 11/12\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 0.0756 - dsc_1: 0.9142 - dsc_2: 0.7850\n",
      "Epoch 12/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0743 - dsc_1: 0.9155 - dsc_2: 0.7864WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "500/500 [==============================] - 54s 108ms/step - loss: 0.0743 - dsc_1: 0.9155 - dsc_2: 0.7864 - val_loss: 0.0945 - val_dsc_1: 0.8943 - val_dsc_2: 0.7279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1f08eb8a20>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Compile model\n",
    "model_128.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
    "    loss={'zones': losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
    "    metrics={'zones': custom.dsc(cls=2)},\n",
    "    experimental_run_tf_function=False)\n",
    "\n",
    "# --- Load data into memory for faster training\n",
    "client.load_data_in_memory()\n",
    "\n",
    "# --- Train the model\n",
    "model_128.fit(\n",
    "    x=gen_train, \n",
    "    steps_per_epoch=500, \n",
    "    epochs=12,\n",
    "    validation_data=gen_valid,\n",
    "    validation_steps=500,\n",
    "    validation_freq=4,\n",
    "    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "swRvKyGiKne1"
   },
   "source": [
    "## 3. Custom architecture (multiple step)\n",
    "\n",
    "Finally, using all customizations described in class, find a top-performing model that yields some incremental benefit over the two baseline models above. A multi-step approach (using the cropped `128 x 128` inputs) will tend to yield improved results. Additional modifications that be used include (but are not limited to):\n",
    "\n",
    "* hybrid 3D/2D network\n",
    "* residual connections\n",
    "* added convolutions between contracting and expanding layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dR-UiM91Kne2"
   },
   "outputs": [],
   "source": [
    "# --- Select shape\n",
    "configs = {'specs': {'xs': {'dat': {'shape': [3, 128, 128, 1]}}}, \n",
    "           'batch': {'size': 12}}\n",
    "\n",
    "# --- Cropped 128 x 128 (multiple step)\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/prostatex-seg', keyword='seg-crp', configs=configs)\n",
    "inputs = client.get_inputs(Input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hn5FQVPJKne4"
   },
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XuJP7Cl7NEDf"
   },
   "outputs": [],
   "source": [
    "# --- Define 2D conv (xy-features)\n",
    "conv_2d = lambda x, filters, strides : layers.Conv3D(\n",
    "    filters=filters, \n",
    "    strides=strides, \n",
    "    kernel_size=(1, 3, 3), \n",
    "    padding='same',\n",
    "    kernel_initializer='he_normal')(x)\n",
    "\n",
    "# --- Define 1D conv (z-features)\n",
    "conv_1d = lambda x, filters, k=2 : layers.Conv3D(\n",
    "    filters=filters,\n",
    "    strides=1,\n",
    "    kernel_size=(k, 1, 1),\n",
    "    padding='valid',\n",
    "    kernel_initializer='he_normal')(x)\n",
    "\n",
    "# --- Define stride-1 3D, stride-2 3D and stride-1 1D (z-subsample) blocks\n",
    "conv1 = lambda filters, x : relu(norm(conv_2d(x, filters, strides=(1, 1, 1))))\n",
    "conv2 = lambda filters, x : relu(norm(conv_2d(x, filters, strides=(1, 2, 2))))\n",
    "convZ = lambda filters, k, x : relu(norm(conv_1d(x, filters, k=k)))\n",
    "\n",
    "# --- Define 2D transpose\n",
    "tran = lambda x, filters : layers.Conv3DTranspose(\n",
    "    filters=filters, \n",
    "    strides=(1, 2, 2),\n",
    "    kernel_size=(1, 3, 3),\n",
    "    padding='same',\n",
    "    kernel_initializer='he_normal')(x)\n",
    "\n",
    "# --- Define transpose block\n",
    "tran2 = lambda filters, x : relu(norm(tran(x, filters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n29VusRXKne5"
   },
   "outputs": [],
   "source": [
    "# --- Define model\n",
    "l1 = conv1(8,  inputs['dat'])\n",
    "l2 = conv1(16, conv2(16, l1))\n",
    "l3 = conv1(32, conv2(32, l2))\n",
    "l4 = conv1(48, convZ(48, 2, conv2(48, l3)))\n",
    "l5 = conv1(64, convZ(64, 2, conv2(64, l4)))\n",
    "l6 =  tran2(48, conv1(48, l5))\n",
    "l7 =  tran2(32, conv1(48, convZ(48, 2, l4) + l6))\n",
    "l8 =  tran2(16, conv1(32, convZ(32, 3, l3) + l7))\n",
    "l9 =  tran2(8,  conv1(16, convZ(16, 3, l2) + l8))\n",
    "l10 = conv1(8,  conv1(8,  convZ(8,  3, l1) + l9))\n",
    "\n",
    "\n",
    "# --- Create logits\n",
    "logits_custom = {}\n",
    "logits_custom['zones'] = layers.Conv3D(\n",
    "    name='zones',\n",
    "    filters=3, \n",
    "    strides=1, \n",
    "    kernel_size=(1, 3, 3), \n",
    "    padding='same',\n",
    "    kernel_initializer='he_normal')(l10)\n",
    "\n",
    "# --- Create model\n",
    "model_custom = Model(inputs=inputs, outputs=logits_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVQydfPDKne9"
   },
   "source": [
    "### Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "id": "0JHPilQjKne-",
    "outputId": "afd68005-fa49-4839-d5b2-3a40c7363095"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-13 11:24:44 ] [====================] 100.000% : Iterating | 000342    WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "Epoch 1/12\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "500/500 [==============================] - 74s 147ms/step - loss: 0.7338 - dsc_1: 0.5808 - dsc_2: 0.3135\n",
      "Epoch 2/12\n",
      "500/500 [==============================] - 74s 147ms/step - loss: 0.1659 - dsc_1: 0.8574 - dsc_2: 0.6651\n",
      "Epoch 3/12\n",
      "500/500 [==============================] - 74s 147ms/step - loss: 0.1205 - dsc_1: 0.8808 - dsc_2: 0.7088\n",
      "Epoch 4/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1029 - dsc_1: 0.8923 - dsc_2: 0.7305WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "500/500 [==============================] - 93s 185ms/step - loss: 0.1029 - dsc_1: 0.8923 - dsc_2: 0.7305 - val_loss: 0.1054 - val_dsc_1: 0.8881 - val_dsc_2: 0.6877\n",
      "Epoch 5/12\n",
      "500/500 [==============================] - 74s 147ms/step - loss: 0.0930 - dsc_1: 0.9012 - dsc_2: 0.7476\n",
      "Epoch 6/12\n",
      "500/500 [==============================] - 74s 147ms/step - loss: 0.0888 - dsc_1: 0.9037 - dsc_2: 0.7574\n",
      "Epoch 7/12\n",
      "500/500 [==============================] - 74s 147ms/step - loss: 0.0836 - dsc_1: 0.9095 - dsc_2: 0.7676\n",
      "Epoch 8/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0788 - dsc_1: 0.9129 - dsc_2: 0.7773WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 0.0788 - dsc_1: 0.9129 - dsc_2: 0.7773 - val_loss: 0.0893 - val_dsc_1: 0.9033 - val_dsc_2: 0.7333\n",
      "Epoch 9/12\n",
      "500/500 [==============================] - 73s 147ms/step - loss: 0.0758 - dsc_1: 0.9161 - dsc_2: 0.7843\n",
      "Epoch 10/12\n",
      "500/500 [==============================] - 73s 147ms/step - loss: 0.0745 - dsc_1: 0.9167 - dsc_2: 0.7866\n",
      "Epoch 11/12\n",
      "500/500 [==============================] - 74s 147ms/step - loss: 0.0724 - dsc_1: 0.9181 - dsc_2: 0.7926\n",
      "Epoch 12/12\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0698 - dsc_1: 0.9223 - dsc_2: 0.7986WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "500/500 [==============================] - 92s 184ms/step - loss: 0.0698 - dsc_1: 0.9223 - dsc_2: 0.7986 - val_loss: 0.0910 - val_dsc_1: 0.9025 - val_dsc_2: 0.7340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1efe677278>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Compile model\n",
    "model_custom.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
    "    loss={'zones': losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
    "    metrics={'zones': custom.dsc(cls=2)},\n",
    "    experimental_run_tf_function=False)\n",
    "\n",
    "client.load_data_in_memory()\n",
    "# --- Train the model\n",
    "model_custom.fit(\n",
    "    x=gen_train, \n",
    "    steps_per_epoch=500, \n",
    "    epochs=12,\n",
    "    validation_data=gen_valid,\n",
    "    validation_steps=500,\n",
    "    validation_freq=4,\n",
    "    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Q2to8b7KnfB"
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "For each of the three models, the following metrics should be calculated for **both the training and validation** cohorts:\n",
    "\n",
    "* Dice score, mean\n",
    "* Dice score, median\n",
    "* Dice score, 25th percentile\n",
    "* Dice score, 75th percentile\n",
    "\n",
    "The Dice score values should be calculated both for peripheral and transitional zone (class 1 and 2); the Dice score for background does not need to be evaluated. As in prior assignments, accuracy is determined on a patient by patient (volume by volume) basis, so please calculate the Dice score values on the entire 3D volume (not slice-by-slice).\n",
    "\n",
    "### Performance\n",
    "\n",
    "The following minimum performance metrics must be met for full credit:\n",
    "\n",
    "1. 2D U-Net, single step (full 256 x 256)\n",
    "\n",
    "* peripheral zone: mean Dice score > 0.75\n",
    "* transitional zone: mean Dice score > 0.55\n",
    "\n",
    "2. 2D U-Net, multiple step (cropped)\n",
    "\n",
    "* peripheral zone: mean Dice score > 0.80\n",
    "* transitional zone: mean Dice score > 0.60\n",
    "\n",
    "3. Custom architecture\n",
    "\n",
    "* peripeheral zone: mean Dice score > 0.85\n",
    "* transitional zone: mean Dice score > 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6lowUSX9KnfC"
   },
   "outputs": [],
   "source": [
    "# --- Create validation generator\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESkg5ThOKnfG"
   },
   "source": [
    "### Results\n",
    "\n",
    "When ready, create a `*.csv` file with your compiled **training and validation** cohort statistics for the three different models. Consider the following table format (although any format that contains the required information is sufficient):\n",
    "\n",
    "```\n",
    "          TRANSITIONAL ZONE                       PERIPHERAL ZONE\n",
    "          mean | median | 25th-tile | 75th-tile | mean | median | 25th-tile | 75th-tile\n",
    "model 1\n",
    "model 2\n",
    "model 3\n",
    "```\n",
    "\n",
    "As above, tables for both training and validation should be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSt9y__SpzUO"
   },
   "outputs": [],
   "source": [
    "def dice(y_true, y_pred, c=1, epsilon=1):\n",
    "    \"\"\"\n",
    "    Method to calculate the Dice score coefficient for given class\n",
    "    \n",
    "    :params\n",
    "    \n",
    "      (np.ndarray) y_true : ground-truth label\n",
    "      (np.ndarray) y_pred : predicted logits scores\n",
    "      (int)             c : class to calculate DSC on\n",
    "    \n",
    "    \"\"\"\n",
    "    assert y_true.ndim == y_pred.ndim\n",
    "    \n",
    "    true = y_true[..., 0] == c\n",
    "    pred = np.argmax(y_pred, axis=-1) == c \n",
    "\n",
    "    A = np.count_nonzero(true & pred) * 2\n",
    "    B = np.count_nonzero(true) + np.count_nonzero(pred) + epsilon\n",
    "    \n",
    "    return A / B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Wbz7h2imT7au",
    "outputId": "b23ebf96-fce1-49f8-db7d-5bc87c4459ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-13 11:55:48 ] [====================] 100.000% : Iterating | 000273    "
     ]
    }
   ],
   "source": [
    "# --- Create validation generator\n",
    "gen_train, gen_valid, client = datasets.prepare(name='mr/prostatex-seg', keyword='seg-256')\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
    "\n",
    "model_1_train_pz = []\n",
    "model_1_train_tz = []\n",
    "\n",
    "for x, y in test_train:\n",
    "  # --- Predict\n",
    "    logits = model.predict(x['dat'])\n",
    "\n",
    "    if type(logits) is dict:\n",
    "        logits = logits['zones']\n",
    "\n",
    "    # --- Argmax\n",
    "    model_1_train_pz.append(dice(y['zones'][0], logits[0], c=1))\n",
    "    model_1_train_tz.append(dice(y['zones'][0], logits[0], c=2))\n",
    "\n",
    "model_1_train_pz = np.array(model_1_train_pz)\n",
    "model_1_train_tz = np.array(model_1_train_tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C2ghgL2Zge9i",
    "outputId": "a1dddff3-5fad-48de-f4ea-37b428561fc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-13 11:56:15 ] [====================] 100.000% : Iterating | 000069    "
     ]
    }
   ],
   "source": [
    "model_1_valid_pz = []\n",
    "model_1_valid_tz = []\n",
    "\n",
    "for x, y in test_valid:\n",
    "    # --- Predict\n",
    "    logits = model.predict(x['dat'])\n",
    "\n",
    "    if type(logits) is dict:\n",
    "        logits = logits['zones']\n",
    "\n",
    "    # --- Argmax\n",
    "    model_1_valid_pz.append(dice(y['zones'][0], logits[0], c=1))\n",
    "    model_1_valid_tz.append(dice(y['zones'][0], logits[0], c=2))\n",
    "    \n",
    "model_1_valid_pz = np.array(model_1_valid_pz)\n",
    "model_1_valid_tz = np.array(model_1_valid_tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "dGF0FZSaqRTL",
    "outputId": "1cd816e2-3560-4e87-a9f4-fad89ad78238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-13 11:56:32 ] [>...................] 2.198% : Iterating | 000006      WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1eefa9bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1eedeb6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "[ 2020-05-13 11:56:34 ] [>...................] 2.564% : Iterating | 000007      WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1eefa9bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1eedeb6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "[ 2020-05-13 11:56:36 ] [>...................] 3.297% : Iterating | 000009      WARNING:tensorflow:7 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1eefa9bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1eedeb6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "[ 2020-05-13 11:56:38 ] [>...................] 4.029% : Iterating | 000011      WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1eefa9bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1eedeb6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "[ 2020-05-13 11:56:39 ] [>...................] 4.762% : Iterating | 000013      WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1eefa9bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1eedeb6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "[ 2020-05-13 11:57:38 ] [====================] 100.000% : Iterating | 000273    "
     ]
    }
   ],
   "source": [
    "gen_train, gen_valid, client = datasets.prepare(name='mr/prostatex-seg', keyword='seg-crp', configs=configs)\n",
    "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
    "\n",
    "model_2_train_pz = []\n",
    "model_2_train_tz = []\n",
    "model_3_train_pz = []\n",
    "model_3_train_tz = []\n",
    "\n",
    "for x, y in test_train:\n",
    "  # --- Predict\n",
    "    logits_128 = model_128.predict(x['dat'])\n",
    "    x['dat'] = np.pad(x['dat'], ((0, 0), (1, 1), (0, 0), (0, 0), (0, 0)))\n",
    "    logits_custom = model_custom.predict(x['dat'])\n",
    "\n",
    "    if type(logits_128) is dict:\n",
    "        logits_128 = logits_128['zones']\n",
    "    if type(logits_custom) is dict:\n",
    "        logits_custom = logits_custom['zones']\n",
    "\n",
    "    # --- Argmax\n",
    "    model_2_train_pz.append(dice(y['zones'][0], logits_128[0], c=1))\n",
    "    model_2_train_tz.append(dice(y['zones'][0], logits_128[0], c=2))\n",
    "\n",
    "    model_3_train_pz.append(dice(y['zones'][0], logits_custom[0], c=1))\n",
    "    model_3_train_tz.append(dice(y['zones'][0], logits_custom[0], c=2))\n",
    "    \n",
    "model_2_train_pz = np.array(model_2_train_pz)\n",
    "model_2_train_tz = np.array(model_2_train_tz)\n",
    "model_3_train_pz = np.array(model_3_train_pz)\n",
    "model_3_train_tz = np.array(model_3_train_tz)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DGFK0fWkc3vo",
    "outputId": "91b0df07-fc88-434b-9860-e248495ec483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-13 11:57:51 ] [====================] 100.000% : Iterating | 000069    "
     ]
    }
   ],
   "source": [
    "model_2_valid_pz = []\n",
    "model_2_valid_tz = []\n",
    "model_3_valid_pz = []\n",
    "model_3_valid_tz = []\n",
    "\n",
    "for x, y in test_valid:\n",
    "    # --- Predict\n",
    "    logits_128 = model_128.predict(x['dat'])\n",
    "    x['dat'] = np.pad(x['dat'], ((0, 0), (1, 1), (0, 0), (0, 0), (0, 0)))\n",
    "    logits_custom = model_custom.predict(x['dat'])\n",
    "\n",
    "    if type(logits_128) is dict:\n",
    "        logits_128 = logits_128['zones']\n",
    "    if type(logits_custom) is dict:\n",
    "        logits_custom = logits_custom['zones']\n",
    "\n",
    "    # --- Argmax\n",
    "\n",
    "    model_2_valid_pz.append(dice(y['zones'][0], logits_128[0], c=1))\n",
    "    model_2_valid_tz.append(dice(y['zones'][0], logits_128[0], c=2))\n",
    "\n",
    "    model_3_valid_pz.append(dice(y['zones'][0], logits_custom[0], c=1))\n",
    "    model_3_valid_tz.append(dice(y['zones'][0], logits_custom[0], c=2))\n",
    "\n",
    "model_2_valid_pz = np.array(model_2_valid_pz)\n",
    "model_2_valid_tz = np.array(model_2_valid_tz)\n",
    "model_3_valid_pz = np.array(model_3_valid_pz)\n",
    "model_3_valid_tz = np.array(model_3_valid_tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LG0CBo36zO7n"
   },
   "outputs": [],
   "source": [
    "# --- Define columns\n",
    "data_train = {'T TRANSITIONAL ZONE mean': [model_1_train_tz.mean(), model_2_train_tz.mean(), model_3_train_tz.mean()],\n",
    "              'T TRANSITIONAL ZONE median': [np.median(model_1_train_tz), np.median(model_2_train_tz), np.median(model_3_train_tz)],\n",
    "              'T TRANSITIONAL ZONE 25th-tile': [np.percentile(model_1_train_tz, 25), np.percentile(model_2_train_tz, 25), np.percentile(model_3_train_tz, 25)],\n",
    "              'T TRANSITIONAL ZONE 75th-tile': [np.percentile(model_1_train_tz, 75), np.percentile(model_2_train_tz, 75), np.percentile(model_3_train_tz, 75)],\n",
    "              'T PERIPHERAL ZONE mean': [model_1_train_pz.mean(), model_2_train_pz.mean(), model_3_train_pz.mean()],\n",
    "              'T PERIPHERAL ZONE median': [np.median(model_1_train_pz), np.median(model_2_train_pz), np.median(model_3_train_pz)],\n",
    "              'T PERIPHERAL ZONE 25th-tile': [np.percentile(model_1_train_pz, 25), np.percentile(model_2_train_pz, 25), np.percentile(model_3_train_pz, 25)],\n",
    "              'T PERIPHERAL ZONE 75th-tile': [np.percentile(model_1_train_pz, 75), np.percentile(model_2_train_pz, 75), np.percentile(model_3_train_pz, 75)]        \n",
    "}\n",
    "df_train = pd.DataFrame(data_train, index=['model 1', 'model 2', 'model 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "lr8yzF0z_R8x",
    "outputId": "f1f50728-538d-4d0a-9d51-2ac2db2b77ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cohort statistics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T TRANSITIONAL ZONE mean</th>\n",
       "      <th>T TRANSITIONAL ZONE median</th>\n",
       "      <th>T TRANSITIONAL ZONE 25th-tile</th>\n",
       "      <th>T TRANSITIONAL ZONE 75th-tile</th>\n",
       "      <th>T PERIPHERAL ZONE mean</th>\n",
       "      <th>T PERIPHERAL ZONE median</th>\n",
       "      <th>T PERIPHERAL ZONE 25th-tile</th>\n",
       "      <th>T PERIPHERAL ZONE 75th-tile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model 1</th>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.767931</td>\n",
       "      <td>0.722961</td>\n",
       "      <td>0.807674</td>\n",
       "      <td>0.901161</td>\n",
       "      <td>0.914520</td>\n",
       "      <td>0.884082</td>\n",
       "      <td>0.926927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model 2</th>\n",
       "      <td>0.799555</td>\n",
       "      <td>0.814830</td>\n",
       "      <td>0.771032</td>\n",
       "      <td>0.843021</td>\n",
       "      <td>0.912978</td>\n",
       "      <td>0.919799</td>\n",
       "      <td>0.900713</td>\n",
       "      <td>0.932697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model 3</th>\n",
       "      <td>0.802659</td>\n",
       "      <td>0.814742</td>\n",
       "      <td>0.773855</td>\n",
       "      <td>0.843967</td>\n",
       "      <td>0.916865</td>\n",
       "      <td>0.926121</td>\n",
       "      <td>0.904203</td>\n",
       "      <td>0.938459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         T TRANSITIONAL ZONE mean  ...  T PERIPHERAL ZONE 75th-tile\n",
       "model 1                  0.757282  ...                     0.926927\n",
       "model 2                  0.799555  ...                     0.932697\n",
       "model 3                  0.802659  ...                     0.938459\n",
       "\n",
       "[3 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training cohort statistics\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FpB1pWGo_0NR"
   },
   "outputs": [],
   "source": [
    "# --- Define columns\n",
    "data_valid = {'V TRANSITIONAL ZONE mean': [model_1_valid_tz.mean(), model_2_valid_tz.mean(), model_3_valid_tz.mean()],\n",
    "              'V TRANSITIONAL ZONE median': [np.median(model_1_valid_tz), np.median(model_2_valid_tz), np.median(model_3_valid_tz)],\n",
    "              'V TRANSITIONAL ZONE 25th-tile': [np.percentile(model_1_valid_tz, 25), np.percentile(model_2_valid_tz, 25), np.percentile(model_3_valid_tz, 25)],\n",
    "              'V TRANSITIONAL ZONE 75th-tile': [np.percentile(model_1_valid_tz, 75), np.percentile(model_2_valid_tz, 75), np.percentile(model_3_valid_tz, 75)],\n",
    "              'V PERIPHERAL ZONE mean': [model_1_valid_pz.mean(), model_2_valid_pz.mean(), model_3_valid_pz.mean()],\n",
    "              'V PERIPHERAL ZONE median': [np.median(model_1_valid_pz), np.median(model_2_valid_pz), np.median(model_3_valid_pz)],\n",
    "              'V PERIPHERAL ZONE 25th-tile': [np.percentile(model_1_valid_pz, 25), np.percentile(model_2_valid_pz, 25), np.percentile(model_3_valid_pz, 25)],\n",
    "              'V PERIPHERAL ZONE 75th-tile': [np.percentile(model_1_valid_pz, 75), np.percentile(model_2_valid_pz, 75), np.percentile(model_3_valid_pz, 75)]        \n",
    "}\n",
    "df_valid = pd.DataFrame(data_valid, index=['model 1', 'model 2', 'model 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "Q-v-3o3D_0yc",
    "outputId": "7460f711-e37c-4252-c367-047400a34460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation cohort statistics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V TRANSITIONAL ZONE mean</th>\n",
       "      <th>V TRANSITIONAL ZONE median</th>\n",
       "      <th>V TRANSITIONAL ZONE 25th-tile</th>\n",
       "      <th>V TRANSITIONAL ZONE 75th-tile</th>\n",
       "      <th>V PERIPHERAL ZONE mean</th>\n",
       "      <th>V PERIPHERAL ZONE median</th>\n",
       "      <th>V PERIPHERAL ZONE 25th-tile</th>\n",
       "      <th>V PERIPHERAL ZONE 75th-tile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model 1</th>\n",
       "      <td>0.701912</td>\n",
       "      <td>0.721722</td>\n",
       "      <td>0.657567</td>\n",
       "      <td>0.767067</td>\n",
       "      <td>0.889729</td>\n",
       "      <td>0.900158</td>\n",
       "      <td>0.872128</td>\n",
       "      <td>0.914436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model 2</th>\n",
       "      <td>0.716508</td>\n",
       "      <td>0.737924</td>\n",
       "      <td>0.650525</td>\n",
       "      <td>0.795677</td>\n",
       "      <td>0.887891</td>\n",
       "      <td>0.896518</td>\n",
       "      <td>0.874417</td>\n",
       "      <td>0.915683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model 3</th>\n",
       "      <td>0.723521</td>\n",
       "      <td>0.750314</td>\n",
       "      <td>0.656455</td>\n",
       "      <td>0.794174</td>\n",
       "      <td>0.892764</td>\n",
       "      <td>0.903859</td>\n",
       "      <td>0.877962</td>\n",
       "      <td>0.922896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V TRANSITIONAL ZONE mean  ...  V PERIPHERAL ZONE 75th-tile\n",
       "model 1                  0.701912  ...                     0.914436\n",
       "model 2                  0.716508  ...                     0.915683\n",
       "model 3                  0.723521  ...                     0.922896\n",
       "\n",
       "[3 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Validation cohort statistics\")\n",
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "hojbPKHaivTT",
    "outputId": "6aa21607-e8d3-427a-ea05-aebf10b33f32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T TRANSITIONAL ZONE mean</th>\n",
       "      <th>T TRANSITIONAL ZONE median</th>\n",
       "      <th>T TRANSITIONAL ZONE 25th-tile</th>\n",
       "      <th>T TRANSITIONAL ZONE 75th-tile</th>\n",
       "      <th>T PERIPHERAL ZONE mean</th>\n",
       "      <th>T PERIPHERAL ZONE median</th>\n",
       "      <th>T PERIPHERAL ZONE 25th-tile</th>\n",
       "      <th>T PERIPHERAL ZONE 75th-tile</th>\n",
       "      <th>V TRANSITIONAL ZONE mean</th>\n",
       "      <th>V TRANSITIONAL ZONE median</th>\n",
       "      <th>V TRANSITIONAL ZONE 25th-tile</th>\n",
       "      <th>V TRANSITIONAL ZONE 75th-tile</th>\n",
       "      <th>V PERIPHERAL ZONE mean</th>\n",
       "      <th>V PERIPHERAL ZONE median</th>\n",
       "      <th>V PERIPHERAL ZONE 25th-tile</th>\n",
       "      <th>V PERIPHERAL ZONE 75th-tile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model 1</th>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.767931</td>\n",
       "      <td>0.722961</td>\n",
       "      <td>0.807674</td>\n",
       "      <td>0.901161</td>\n",
       "      <td>0.914520</td>\n",
       "      <td>0.884082</td>\n",
       "      <td>0.926927</td>\n",
       "      <td>0.701912</td>\n",
       "      <td>0.721722</td>\n",
       "      <td>0.657567</td>\n",
       "      <td>0.767067</td>\n",
       "      <td>0.889729</td>\n",
       "      <td>0.900158</td>\n",
       "      <td>0.872128</td>\n",
       "      <td>0.914436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model 2</th>\n",
       "      <td>0.799555</td>\n",
       "      <td>0.814830</td>\n",
       "      <td>0.771032</td>\n",
       "      <td>0.843021</td>\n",
       "      <td>0.912978</td>\n",
       "      <td>0.919799</td>\n",
       "      <td>0.900713</td>\n",
       "      <td>0.932697</td>\n",
       "      <td>0.716508</td>\n",
       "      <td>0.737924</td>\n",
       "      <td>0.650525</td>\n",
       "      <td>0.795677</td>\n",
       "      <td>0.887891</td>\n",
       "      <td>0.896518</td>\n",
       "      <td>0.874417</td>\n",
       "      <td>0.915683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model 3</th>\n",
       "      <td>0.802659</td>\n",
       "      <td>0.814742</td>\n",
       "      <td>0.773855</td>\n",
       "      <td>0.843967</td>\n",
       "      <td>0.916865</td>\n",
       "      <td>0.926121</td>\n",
       "      <td>0.904203</td>\n",
       "      <td>0.938459</td>\n",
       "      <td>0.723521</td>\n",
       "      <td>0.750314</td>\n",
       "      <td>0.656455</td>\n",
       "      <td>0.794174</td>\n",
       "      <td>0.892764</td>\n",
       "      <td>0.903859</td>\n",
       "      <td>0.877962</td>\n",
       "      <td>0.922896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         T TRANSITIONAL ZONE mean  ...  V PERIPHERAL ZONE 75th-tile\n",
       "model 1                  0.757282  ...                     0.914436\n",
       "model 2                  0.799555  ...                     0.915683\n",
       "model 3                  0.802659  ...                     0.922896\n",
       "\n",
       "[3 rows x 16 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([df_train, df_valid.reindex(df_train.index)], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o6TadA7MKnfH"
   },
   "outputs": [],
   "source": [
    "# --- Serialize *.csv\n",
    "fname = '{}/models/midterm/results.csv'.format(MOUNT_ROOT)\n",
    "os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "result.to_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QCuXFrdR50kZ"
   },
   "outputs": [],
   "source": [
    "fname = '{}/models/midterm/model1.hdf5'.format(MOUNT_ROOT)\n",
    "os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "model.save(fname)\n",
    "\n",
    "fname = '{}/models/midterm/model2.hdf5'.format(MOUNT_ROOT)\n",
    "os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "model_128.save(fname)\n",
    "\n",
    "fname = '{}/models/midterm/model3.hdf5'.format(MOUNT_ROOT)\n",
    "os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "model_custom.save(fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOvgPFZjKnfL"
   },
   "source": [
    "# Summary\n",
    "\n",
    "In addition to algorithm training as above, a 1-2 page write-up is required for this project. The goal is to *briefly* summarize algorithm design and key results. The write-up should be divided into three sections: methods; results; discussion.\n",
    "\n",
    "### Methods\n",
    "\n",
    "In this section, include details such as:\n",
    "\n",
    "* **Data**: How much data was used. How many cases were utilized for training and validation?\n",
    "* **Network design**: What are the different network architectures? How many layers and parameters? Were 2D or 3D operations used? Recall that the `model.summary(...)` can be used to provide key summary statistics for this purpose. If desired, feel free to include a model figure or diagram.\n",
    "* **Implementation**: How was training implemented. What are the key hyperparameters (e.g. learning rate, batch size, optimizer, etc)? How many training iterations were required for convergence? Did these hyperparameters change during the course of training?\n",
    "* **Statistics**: What statistics do you plan to use to evaluate model accuracy? \n",
    "\n",
    "### Results\n",
    "\n",
    "In this section, briefly summarize experimental results (a few sentences), and include the result table(s) as derived above.\n",
    "\n",
    "### Discussion\n",
    "\n",
    "Were the results expected or unexpected? What accounts for the differences in performance between the algorithms? Was segmentation performance within the peripheral and transitional zones affected equally in all models? Why or why not? Feel free to elaborate on any additional observations noted during the course of this expierment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5veJvj87KnfM"
   },
   "source": [
    "# Submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D6TeMaA6KnfN"
   },
   "source": [
    "### Canvas\n",
    "\n",
    "Once you have completed this assignment, download the necessary files from Google Colab and your Google Drive. You will then need to submit the following items:\n",
    "\n",
    "* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n",
    "* final (results) spreadsheet: `[UCInetID]_results.csv`\n",
    "* final (trained) model: `[UCInetID]_model.hdf5`\n",
    "\n",
    "**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooke file would be submitted under the name `panteater_notebook.ipynb`, his spreadshhet would be submitted under the name `panteater_results.csv` and and his model file would be submitted under the name `panteater_model.hdf5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1P9gX1udo7ih"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "GaFUB_1yKnen",
    "RAi6DA9vKnes"
   ],
   "name": "midterm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
