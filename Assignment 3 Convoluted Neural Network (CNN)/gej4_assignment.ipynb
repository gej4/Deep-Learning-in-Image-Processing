{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNvGQSxXRlRh",
        "colab_type": "text"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "In this assignment we will train a convolutional neural network (CNN) on the CIFAR-10 dataset.\n",
        "\n",
        "This assignment is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTbUhjkVRlRi",
        "colab_type": "text"
      },
      "source": [
        "### Submission\n",
        "\n",
        "Once complete, the following items must be submitted:\n",
        "\n",
        "* final `*.ipynb` notebook (push to https://github.com/[username]/cs190/cnn/assignment.ipynb)\n",
        "* final trained `*.hdf5` model file\n",
        "* final compiled `*.csv` file with performance statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "56d3oMiMw8Wm"
      },
      "source": [
        "# Google Colab\n",
        "\n",
        "The following lines of code will configure your Google Colab environment for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYsjUJ-YRlRk",
        "colab_type": "text"
      },
      "source": [
        "### Enable GPU runtime\n",
        "\n",
        "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
        "\n",
        "```\n",
        "Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9udZqHwRlRl",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive\n",
        "\n",
        "The Google Colab environment is transient and will reset after any prolonged break in activity. To retain important and/or large files between sessions, use the following lines of code to mount your personal Google drive to this Colab instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkZ5ThQTRlRm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "0b724bfc-1e53-44f1-9e30-bdc412ded799"
      },
      "source": [
        "try:\n",
        "    # --- Mount gdrive to /content/drive/My Drive/\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "except: pass"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny1xBqjBRlRs",
        "colab_type": "text"
      },
      "source": [
        "Throughout this assignment we will use the following global `MOUNT_ROOT` variable to reference a location to store long-term data. If you are using a local Jupyter server and/or wish to store your data elsewhere, please update this variable now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i2EPsvURlRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Set data directory\n",
        "MOUNT_ROOT = '/content/drive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDRy4d3NRlRv",
        "colab_type": "text"
      },
      "source": [
        "### Select Tensorflow library version\n",
        "\n",
        "This assignment will use the (new) Tensorflow 2.0 library. Use the following line of code to select this updated version:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK7mY63WRlRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Select Tensorflow 2.0 (only in Google Colab)\n",
        "% tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsN8eEgZRlRz",
        "colab_type": "text"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0C1HCCsRlRz",
        "colab_type": "text"
      },
      "source": [
        "### Jarvis library\n",
        "\n",
        "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ5rqnfDRlR0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "47c011a3-95c2-40df-bdea-997a663ad7e6"
      },
      "source": [
        "# --- Install jarvis (only in Google Colab or local runtime)\n",
        "% pip install jarvis-md"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jarvis-md in /usr/local/lib/python3.6/dist-packages (0.0.1a3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.0.3)\n",
            "Requirement already satisfied: pyyaml>=5.2 in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (5.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.21.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.18.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->jarvis-md) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->jarvis-md) (2018.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ofACgIgRlR4",
        "colab_type": "text"
      },
      "source": [
        "### Imports\n",
        "\n",
        "Use the following lines to import any additional needed libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWSC6UgaRlR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, numpy as np, pandas as pd\n",
        "from tensorflow import losses, optimizers\n",
        "from tensorflow.keras import Input, Model, models, layers\n",
        "from jarvis.train import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlXkk8EsRlR8",
        "colab_type": "text"
      },
      "source": [
        "# Data\n",
        "\n",
        "As in the tutorial, data for this assignment will consist of the CIFAR-10 dataset comprising 10 different everyday objects (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck). The following lines of code will:\n",
        "\n",
        "1. Download the dataset (if not already present) \n",
        "2. Prepare the necessary Python generators to iterate through dataset\n",
        "3. Prepare the corresponding Tensorflow Input(...) objects for model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23mQVE9_RlR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f10e6e2-4c0e-4b8d-fc72-9f98590518a6"
      },
      "source": [
        "# --- Download dataset\n",
        "datasets.download(name='cifar')\n",
        "\n",
        "# --- Prepare generators and model inputs\n",
        "gen_train, gen_valid, client = datasets.prepare(name='cifar')\n",
        "inputs = client.get_inputs(Input)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[ 2020-04-20 07:47:06 ] [====================] 100.000% : Iterating | 000001    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjn0Yr3ARlSA",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "In this assignment we will train a basic convolutional neural network on the CIFAR-10 dataset. At minumum you must include the following baseline techniques covered in the tutorial:\n",
        "\n",
        "* convolutional operations\n",
        "* batch normalization\n",
        "* activation function\n",
        "* subsampling\n",
        "\n",
        "You are also **encouraged** to try different permuations and customizations to achieve optimal validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOS3z1auRlSA",
        "colab_type": "text"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9k0YN0karal",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "cefe5d78-5968-4174-d778-fe790ed22c52"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "kwargs = {\n",
        "    'kernel_size': (3, 3),\n",
        "    'padding': 'same'\n",
        "    'kernel_regularizer': regularizers.l2(0.01)}\n",
        "\n",
        "relu = lambda x: layers.LeakyReLU()(x)\n",
        "norm = lambda x: layers.BatchNormalization()(x)\n",
        "conv = lambda x, filters, strides : layers.Conv2D(filters=filters, strides=strides, **kwargs)(x)\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(2, 2))))\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-bca964acaef0>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    'kernel_regularizer': regularizers.l2(0.01)}\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3F7fP-QRlSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Define dropout\n",
        "drop = layers.Dropout(rate=0.25)\n",
        "\n",
        "# --- Define series of blocks\n",
        "l1 = conv1(16, inputs['dat'])\n",
        "l2 = conv1(24, conv2(24, l1))\n",
        "l3 = conv1(32, conv2(32, l2))\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "#print (l4.shape)\n",
        "\n",
        "f0 = layers.Flatten()(l4)\n",
        "#print (f0.shape)\n",
        "hidden_size = 64\n",
        "f1 = drop(layers.Dense(hidden_size, activation='relu')(f0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JROCK3OZRlSD",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQzTy167RlSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Compile model\n",
        "logits = {}\n",
        "logits['class'] = layers.Dense(10, name='class')(f1)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=logits)\n",
        "\n",
        "# --- Compile model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=2e-4), \n",
        "    loss={'class': losses.SparseCategoricalCrossentropy(from_logits=True)}, \n",
        "    metrics={'class': 'sparse_categorical_accuracy'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwuSiw2sRlSI",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX6x7dShRlSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "outputId": "1dfb614b-d7d7-44d9-b504-529bcf8d1a53"
      },
      "source": [
        "model.fit(\n",
        "    x=gen_train, \n",
        "    steps_per_epoch=250, \n",
        "    epochs=20,\n",
        "    validation_data=gen_valid,\n",
        "    validation_steps=250,\n",
        "    validation_freq=4)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 2.1229 - sparse_categorical_accuracy: 0.2306\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 1.8391 - sparse_categorical_accuracy: 0.3406\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 1.7013 - sparse_categorical_accuracy: 0.3868\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 13s 53ms/step - loss: 1.6314 - sparse_categorical_accuracy: 0.4146 - val_loss: 1.5239 - val_sparse_categorical_accuracy: 0.4493\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 1.5487 - sparse_categorical_accuracy: 0.4424\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 1.4873 - sparse_categorical_accuracy: 0.4629\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 1.4233 - sparse_categorical_accuracy: 0.4911\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 13s 52ms/step - loss: 1.4064 - sparse_categorical_accuracy: 0.4966 - val_loss: 1.3350 - val_sparse_categorical_accuracy: 0.5229\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 1.3735 - sparse_categorical_accuracy: 0.5071\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 1.3338 - sparse_categorical_accuracy: 0.5281\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 1.3099 - sparse_categorical_accuracy: 0.5359\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 13s 52ms/step - loss: 1.2928 - sparse_categorical_accuracy: 0.5371 - val_loss: 1.2168 - val_sparse_categorical_accuracy: 0.5591\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 1.2410 - sparse_categorical_accuracy: 0.5554\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 1.2234 - sparse_categorical_accuracy: 0.5599\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 1.1846 - sparse_categorical_accuracy: 0.5778\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 13s 52ms/step - loss: 1.1770 - sparse_categorical_accuracy: 0.5813 - val_loss: 1.1519 - val_sparse_categorical_accuracy: 0.5916\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 1.1870 - sparse_categorical_accuracy: 0.5760\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 1.1775 - sparse_categorical_accuracy: 0.5836\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 1.1197 - sparse_categorical_accuracy: 0.6044\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 13s 52ms/step - loss: 1.0840 - sparse_categorical_accuracy: 0.6160 - val_loss: 1.1389 - val_sparse_categorical_accuracy: 0.5959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faaddb41b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mux_p5mzRlSP",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Based on the tutorial discussion, use the following cells to check your algorithm performance. Consider loading a saved model and running prediction using `model.predict(...)` on the data aggregated via a test generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ferlzbCxRlSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1f0c7e7-d356-4426-ffc3-e91cd140b2e4"
      },
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True)\n",
        "\n",
        "# --- Aggregate all examples\n",
        "xs = []\n",
        "ys = []\n",
        "\n",
        "for x, y in test_valid:\n",
        "    xs.append(x['dat'])\n",
        "    ys.append(y['class'])\n",
        "\n",
        "xs = np.concatenate(xs)\n",
        "ys = np.concatenate(ys)\n",
        "# --- Predict\n",
        "logits = model.predict(xs)\n",
        "\n",
        "if type(logits) is dict:\n",
        "    logits = logits['class']\n",
        "\n",
        "# --- Argmax\n",
        "pred = np.argmax(logits, axis=1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2020-04-20 08:37:58 ] [====================] 100.000% : Iterating | 012000    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qtcmdwHRlSS",
        "colab_type": "text"
      },
      "source": [
        "**Note**: this cell is used only to check for model performance. It will not be graded. Once you are satisfied with your model, proceed to submission of your assignment below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOnSasTRRlSS",
        "colab_type": "text"
      },
      "source": [
        "### Results\n",
        "\n",
        "When ready, create a `*.csv` file with your compiled **validation** cohort statistics. There is no need to submit training performance accuracy. As in the tutorial, ensure that there are at least three columns in the `*.csv` file:\n",
        "\n",
        "* true (ground-truth)\n",
        "* pred (prediction)\n",
        "* corr (correction prediction, True or False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_AY88u3RlST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Create *.csv\n",
        "df = pd.DataFrame(index=np.arange(pred.size))\n",
        "\n",
        "# --- Define columns\n",
        "df['true'] = ys[:, 0]\n",
        "df['pred'] = pred\n",
        "df['corr'] = df['true'] == df['pred']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxXJ2Pd2vaRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Serialize *.csv\n",
        "fname = '{}/models/cnn/results.csv'.format(MOUNT_ROOT)\n",
        "os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
        "df.to_csv(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8ASyE7fRlSV",
        "colab_type": "text"
      },
      "source": [
        "# Submission\n",
        "\n",
        "Use the following line to save your model for submission (in Google Colab this should save your model file into your personal Google Drive):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mK8GkqfRlSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Serialize a model\n",
        "fname = '{}/models/cnn/final.hdf5'.format(MOUNT_ROOT)\n",
        "os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
        "model.save(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNWoNcQPRlSY",
        "colab_type": "text"
      },
      "source": [
        "### Canvas\n",
        "\n",
        "Once you have completed this assignment, download the necessary files from Google Colab and your Google Drive. You will then need to submit the following items:\n",
        "\n",
        "* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n",
        "* final (results) spreadsheet: `[UCInetID]_results.csv`\n",
        "* final (trained) model: `[UCInetID]_model.hdf5`\n",
        "\n",
        "**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooke file would be submitted under the name `panteater_notebook.ipynb`, his spreadshhet would be submitted under the name `panteater_results.csv` and and his model file would be submitted under the name `panteater_model.hdf5`."
      ]
    }
  ]
}