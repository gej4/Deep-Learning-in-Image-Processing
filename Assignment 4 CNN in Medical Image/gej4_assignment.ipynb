{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD8yLpgexRSC",
        "colab_type": "text"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "In this assignment we will train a convolutional neural network (CNN) to predict the imaging series protocol on prostate MRI. Identifying the correct series of interest if a key first step in most medical imaging problems. Instead of relying on manual DICOM header values which are prone to error, the trained CNN created as part of this exercise will ensure that any downstream algorithms can be executed with high accuracy.\n",
        "\n",
        "This assignment is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFfJIsCSxRSD",
        "colab_type": "text"
      },
      "source": [
        "### Submission\n",
        "\n",
        "Once complete, the following items must be submitted:\n",
        "\n",
        "* final `*.ipynb` notebook (push to https://github.com/[username]/cs190/cnn/assignment.ipynb)\n",
        "* final trained `*.hdf5` model file\n",
        "* final compiled `*.csv` file with performance statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "56d3oMiMw8Wm"
      },
      "source": [
        "# Google Colab\n",
        "\n",
        "The following lines of code will configure your Google Colab environment for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR8DMt8ExRSE",
        "colab_type": "text"
      },
      "source": [
        "### Enable GPU runtime\n",
        "\n",
        "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
        "\n",
        "```\n",
        "Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_yJ9RPExRSE",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive\n",
        "\n",
        "The Google Colab environment is transient and will reset after any prolonged break in activity. To retain important and/or large files between sessions, use the following lines of code to mount your personal Google drive to this Colab instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odeoJ4Q6xRSF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "cf1a60ad-ce82-40e6-da48-7d191be471e1"
      },
      "source": [
        "try:\n",
        "    # --- Mount gdrive to /content/drive/My Drive/\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "except: pass"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH5FkuP3xRSK",
        "colab_type": "text"
      },
      "source": [
        "Throughout this assignment we will use the following global `MOUNT_ROOT` variable to reference a location to store long-term data. If you are using a local Jupyter server and/or wish to store your data elsewhere, please update this variable now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUo_p7UrxRSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Set data directory\n",
        "MOUNT_ROOT = '/content/drive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkuB0jUTxRSR",
        "colab_type": "text"
      },
      "source": [
        "### Select Tensorflow library version\n",
        "\n",
        "This assignment will use the (new) Tensorflow 2.0 library. Use the following line of code to select this updated version:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kgChw6SxRSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Select Tensorflow 2.0 (only in Google Colab)\n",
        "% tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E89q5FYUxRSU",
        "colab_type": "text"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnWt1R3MxRSV",
        "colab_type": "text"
      },
      "source": [
        "### Jarvis library\n",
        "\n",
        "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhG8ID1xxRSV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "3832eef3-51db-471c-82fc-94773fd2204c"
      },
      "source": [
        "# --- Install jarvis (only in Google Colab or local runtime)\n",
        "% pip install jarvis-md"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jarvis-md\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/f2/af97d396d730cb0527875f1bbf2ef8bf636e5f60a4183b2031658d99dfca/jarvis_md-0.0.1a5-py3-none-any.whl (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 24.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 29.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 30kB 32.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 40kB 34.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 51kB 37.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 24.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 30.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 33.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40kB 36.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 38.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61kB 39.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71kB 40.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81kB 40.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92kB 41.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102kB 41.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112kB 41.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122kB 41.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133kB 41.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143kB 41.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153kB 41.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163kB 41.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174kB 41.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184kB 41.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194kB 41.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204kB 41.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215kB 41.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225kB 41.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235kB 41.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245kB 41.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256kB 41.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266kB 41.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 41.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.18.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.21.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (3.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->jarvis-md) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->jarvis-md) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->jarvis-md) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (3.0.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (1.2.0)\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=520df6e8f0bc42de9b2b25a9de7b2588dc41b7672f1e6f0480a9b9161496ef0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml, jarvis-md\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed jarvis-md-0.0.1a5 pyyaml-5.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STfWz44jxRSY",
        "colab_type": "text"
      },
      "source": [
        "### Imports\n",
        "\n",
        "Use the following lines to import any additional needed libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM1URsVMxRSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, numpy as np, pandas as pd\n",
        "from tensorflow import losses, optimizers\n",
        "from tensorflow.keras import Input, Model, models, layers\n",
        "from jarvis.train import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1oiZO9DxRSd",
        "colab_type": "text"
      },
      "source": [
        "# Data\n",
        "\n",
        "As in the tutorial, data for this assignment will consist of prostate MRI exams. Each image will consist of one of four different sequences (T2, low b-value DWI, high b-value DWI, ADC). In this initial exercise, the goal is to simply develop an algorith that is capable of differentiating image type so that downstream models for cancer prediction can be used properly. The following lines of code will:\n",
        "\n",
        "1. Download the dataset (if not already present) \n",
        "2. Prepare the necessary Python generators to iterate through dataset\n",
        "3. Prepare the corresponding Tensorflow Input(...) objects for model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlKww-UNxRSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "852232ed-1652-4664-b8a9-2d38c660d9c3"
      },
      "source": [
        "# --- Download dataset\n",
        "datasets.download(name='mr/prostatex')\n",
        "\n",
        "# --- Prepare generators and model inputs\n",
        "gen_train, gen_valid, client = datasets.prepare(name='mr/prostatex')\n",
        "inputs = client.get_inputs(Input)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2020-04-27 17:54:47 ] [====================] 100.000% : Extracting archive (0001377 / 0001377) "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz_0lGV0xRSh",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "In this assignment we will train a basic convolutional neural network to predict the correct imaging series protocol on prostate MRI. At minumum you must include one of the following modern CNN architecture motifs techniques covered in the tutorial:\n",
        "\n",
        "* residual function with bottleneck operation\n",
        "* Inception module\n",
        "\n",
        "You are also **encouraged** to try different permuations and customizations to achieve optimal validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io6TOSxexRSi",
        "colab_type": "text"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUrmYfYrxRSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Define model\n",
        "conv = lambda x, filters,kernel_size : layers.Conv2D(\n",
        "    filters=filters, \n",
        "    kernel_size=kernel_size, \n",
        "    padding='same')(x)\n",
        "\n",
        "proj = lambda filters, x : layers.Conv2D(\n",
        "    filters=filters, \n",
        "    strides=1, \n",
        "    kernel_size=(1, 1),\n",
        "    padding='same')(x)\n",
        "\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.LeakyReLU()(x)\n",
        "pool = lambda x : layers.MaxPool2D(pool_size=(3, 3), strides=1, padding='same')(x)\n",
        "\n",
        "# --- Define 1x1, 3x3 and 5x5 convs\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=1)))\n",
        "conv3 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=3)))\n",
        "conv5 = lambda filters, x : relu(norm(conv(x, filters, kernel_size=5)))\n",
        "mpool = lambda x : relu(norm(pool(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzcfEHVj0YOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Define first layer operation\n",
        "l1 = conv3(16, inputs['dat'])\n",
        "\n",
        "# --- Define four different paths\n",
        "filters = 4\n",
        "b1 = proj(filters, l1)\n",
        "\n",
        "p1 = conv1(filters, l1)\n",
        "p2 = conv3(filters, b1)\n",
        "p3 = conv5(filters, b1)\n",
        "p4 = proj(filters, mpool(l1))\n",
        "\n",
        "# --- Concatenate\n",
        "l2 = layers.Concatenate()([p1, p2, p3, p4])\n",
        "\n",
        "f0 = layers.Flatten()(l2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6NSZ28B0U6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logits = {}\n",
        "logits['class'] = layers.Dense(4, name='class')(f0)\n",
        "\n",
        "# --- Create model\n",
        "model = Model(inputs=inputs, outputs=logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3vbcbn_xRSl",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04_SIcJrxRSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Compile model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=2e-4), \n",
        "    loss={'class': losses.SparseCategoricalCrossentropy(from_logits=True)}, \n",
        "    metrics={'class': 'sparse_categorical_accuracy'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rGaFZpOxRSp",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TXEg678xRSp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "a7fe434b-e106-4714-e18d-4758ee8183d7"
      },
      "source": [
        "model.fit(\n",
        "    x=gen_train, \n",
        "    steps_per_epoch=250, \n",
        "    epochs=12,\n",
        "    validation_data=gen_valid,\n",
        "    validation_steps=250,\n",
        "    validation_freq=4)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "250/250 [==============================] - 35s 139ms/step - loss: 2.3670 - sparse_categorical_accuracy: 0.8975\n",
            "Epoch 2/12\n",
            "250/250 [==============================] - 35s 139ms/step - loss: 1.0436 - sparse_categorical_accuracy: 0.9522\n",
            "Epoch 3/12\n",
            "250/250 [==============================] - 35s 139ms/step - loss: 0.7434 - sparse_categorical_accuracy: 0.9608\n",
            "Epoch 4/12\n",
            "250/250 [==============================] - 62s 249ms/step - loss: 0.4773 - sparse_categorical_accuracy: 0.9655 - val_loss: 0.3653 - val_sparse_categorical_accuracy: 0.9778\n",
            "Epoch 5/12\n",
            "250/250 [==============================] - 35s 139ms/step - loss: 0.4746 - sparse_categorical_accuracy: 0.9707\n",
            "Epoch 6/12\n",
            "250/250 [==============================] - 35s 138ms/step - loss: 0.5006 - sparse_categorical_accuracy: 0.9700\n",
            "Epoch 7/12\n",
            "250/250 [==============================] - 34s 138ms/step - loss: 0.3707 - sparse_categorical_accuracy: 0.9765\n",
            "Epoch 8/12\n",
            "250/250 [==============================] - 62s 246ms/step - loss: 0.4564 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.4301 - val_sparse_categorical_accuracy: 0.9802\n",
            "Epoch 9/12\n",
            "250/250 [==============================] - 35s 139ms/step - loss: 0.4064 - sparse_categorical_accuracy: 0.9738\n",
            "Epoch 10/12\n",
            "250/250 [==============================] - 35s 139ms/step - loss: 0.4122 - sparse_categorical_accuracy: 0.9747\n",
            "Epoch 11/12\n",
            "250/250 [==============================] - 35s 139ms/step - loss: 0.3925 - sparse_categorical_accuracy: 0.9753\n",
            "Epoch 12/12\n",
            "250/250 [==============================] - 62s 249ms/step - loss: 0.4531 - sparse_categorical_accuracy: 0.9735 - val_loss: 0.2984 - val_sparse_categorical_accuracy: 0.9773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcf5c195550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls__u5szxRSv",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Based on the tutorial discussion, use the following cells to check your algorithm performance. Consider loading a saved model and running prediction using `model.predict(...)` on the data aggregated via a test generator.\n",
        "\n",
        "**Important**: In this assignment, you must obtain >90% performance accuracy to recieve full credit. Accuracy is determined on a patient by patient (volume by volume) basis, so please *aggregate* results per volume while calculating your performance accuracy here. One common approach is to take the mean prediction across the volume for final prediction; however many altneratives exist. If you determine a better method to calculate accuracy, feel free to implement here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_lC2vwuxRSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True, expand=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra-UwFIexRSy",
        "colab_type": "text"
      },
      "source": [
        "**Note**: this cell is used only to check for model performance prior to submission. It will not be graded. Once submitted, your model will be benchmarked against the (same) validation cohort to determine final algorithm performance and grade. If your evaluation code above is correct the algorithm accuracy should match and you can confident that you will recieve full credit for the assignment. Once you are satisfied with your model, proceed to submission of your assignment below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeTQfG_6xRSy",
        "colab_type": "text"
      },
      "source": [
        "### Results\n",
        "\n",
        "When ready, create a `*.csv` file with your compiled **validation** cohort statistics. There is no need to submit training performance accuracy. As in the tutorial, ensure that there are at least three columns in the `*.csv` file:\n",
        "\n",
        "* true (ground-truth)\n",
        "* pred (prediction)\n",
        "* corr (correction prediction, True or False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjglBNzvxRSz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d26dbd82-51b2-4342-f6ef-d06a35d83286"
      },
      "source": [
        "\n",
        "trues = []\n",
        "preds = []\n",
        "\n",
        "for x, y in test_valid:\n",
        "    \n",
        "    # --- Predict\n",
        "    logits = model.predict(x['dat'][0])\n",
        "\n",
        "    if type(logits) is dict:\n",
        "        logits = logits['class']\n",
        "\n",
        "    # --- Argmax\n",
        "    pred = np.argmax(logits, axis=1)\n",
        "\n",
        "    trues.append(y['class'][0, 0])\n",
        "    preds.append(int(np.round(pred.mean())))\n",
        "\n",
        "trues = np.array(trues)\n",
        "preds = np.array(preds)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2020-04-27 18:21:00 ] [====================] 100.000% : Iterating | 000208    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l7Ho-gM3nWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5038b94-75e8-4f8e-e916-18b208ac5f6f"
      },
      "source": [
        "# --- Create *.csv\n",
        "df = pd.DataFrame(index=np.arange(preds.size))\n",
        "\n",
        "# --- Define columns\n",
        "df['true'] = trues\n",
        "df['pred'] = preds\n",
        "df['corr'] = df['true'] == df['pred']\n",
        "\n",
        "# --- Print accuracy\n",
        "print(df['corr'].mean())           "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4WWd2iS4M1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Serialize *.csv\n",
        "fname = '{}/models/series_id/results.csv'.format(MOUNT_ROOT)\n",
        "os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
        "df.to_csv(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YbYgjbRxRS1",
        "colab_type": "text"
      },
      "source": [
        "# Submission\n",
        "\n",
        "Use the following line to save your model for submission (in Google Colab this should save your model file into your personal Google Drive):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0-PhFMOxRS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Serialize a model\n",
        "fname = '{}/models/series_id/final.hdf5'.format(MOUNT_ROOT)\n",
        "os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
        "model.save(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1YWclMYxRS3",
        "colab_type": "text"
      },
      "source": [
        "### Canvas\n",
        "\n",
        "Once you have completed this assignment, download the necessary files from Google Colab and your Google Drive. You will then need to submit the following items:\n",
        "\n",
        "* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n",
        "* final (results) spreadsheet: `[UCInetID]_results.csv`\n",
        "* final (trained) model: `[UCInetID]_model.hdf5`\n",
        "\n",
        "**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooke file would be submitted under the name `panteater_notebook.ipynb`, his spreadshhet would be submitted under the name `panteater_results.csv` and and his model file would be submitted under the name `panteater_model.hdf5`."
      ]
    }
  ]
}