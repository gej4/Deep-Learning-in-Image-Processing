{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbMkV0Gbg_Ft",
        "colab_type": "text"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "In this assignment we will create a high sensitivity detector for pulmonary infection (pneumonia) on chest radiographs. The goal is to optimize for model sensitivity while preseverving a minimum Dice score performance for overall spatial overalp.\n",
        "\n",
        "This assignment is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M82IQLcg_Fu",
        "colab_type": "text"
      },
      "source": [
        "### Submission\n",
        "\n",
        "Once complete, the following items must be submitted:\n",
        "\n",
        "* final `*.ipynb` notebook\n",
        "* final trained `*.hdf5` model file\n",
        "* final compiled `*.csv` file with performance statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "56d3oMiMw8Wm"
      },
      "source": [
        "# Google Colab\n",
        "\n",
        "The following lines of code will configure your Google Colab environment for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZK_bA9cg_Fw",
        "colab_type": "text"
      },
      "source": [
        "### Enable GPU runtime\n",
        "\n",
        "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
        "\n",
        "```\n",
        "Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oce7j8vZg_Fx",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive\n",
        "\n",
        "The Google Colab environment is transient and will reset after any prolonged break in activity. To retain important and/or large files between sessions, use the following lines of code to mount your personal Google drive to this Colab instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzd7LzrNg_Fx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "4c54eee1-2d84-47ba-8010-0ece1b09641a"
      },
      "source": [
        "try:\n",
        "    # --- Mount gdrive to /content/drive/My Drive/\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "except: pass"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ugRFjeJg_F5",
        "colab_type": "text"
      },
      "source": [
        "Throughout this assignment we will use the following global `MOUNT_ROOT` variable to reference a location to store long-term data. If you are using a local Jupyter server and/or wish to store your data elsewhere, please update this variable now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KXSkbikg_F5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Set data directory\n",
        "MOUNT_ROOT = '/content/drive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJH0Qrn5g_F9",
        "colab_type": "text"
      },
      "source": [
        "### Select Tensorflow library version\n",
        "\n",
        "This assignment will use the (new) Tensorflow 2.0 library. Use the following line of code to select this updated version:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO_cfZP8g_F9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8c694f2-8bb4-4c2b-b689-b3894decf853"
      },
      "source": [
        "# --- Select Tensorflow 2.0 (only in Google Colab)\n",
        "% tensorflow_version 2.x\n",
        "% pip install tensorflow-gpu==2.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/93/c7bca39b23aae45cd2e85ad3871c81eccc63b9c5276e926511e2e5b0879d/tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 26kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (0.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.12.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 55.4MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (0.34.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.18.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (3.2.1)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.29.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu==2.1) (46.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (4.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (1.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (2020.4.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=7c22dde019724d36e107aa9172fea2bd5268e3be68cf6fddef7bb12df74e7f60\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 2.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, gast, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "Successfully installed gast-0.2.2 tensorboard-2.1.1 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pp_f4Gwg_GB",
        "colab_type": "text"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oDqzfmLg_GB",
        "colab_type": "text"
      },
      "source": [
        "### Jarvis library\n",
        "\n",
        "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaRCaFl6g_GC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "fb814348-9d7e-43a8-c5f9-3b5375b2a0a8"
      },
      "source": [
        "# --- Install jarvis (only in Google Colab or local runtime)\n",
        "% pip install jarvis-md"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jarvis-md\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/21/66d19a89c4f2a1119d204ad3422a26655840987649d2cdd11c5cc27cfb02/jarvis_md-0.0.1a9-py3-none-any.whl (69kB)\n",
            "\r\u001b[K     |████▊                           | 10kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 30kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.18.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.23.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (3.2.1)\n",
            "Collecting pyyaml>=5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->jarvis-md) (1.12.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (3.0.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->jarvis-md) (2018.9)\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=ddb00932d0cea26ca03ac282c7087012c2cdee0364e9e8a5729b9912a0a11d98\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml, jarvis-md\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed jarvis-md-0.0.1a9 pyyaml-5.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY8HMzp3g_GF",
        "colab_type": "text"
      },
      "source": [
        "### Imports\n",
        "\n",
        "Use the following lines to import any additional needed libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5H03QXFg_GG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np, pandas as pd\n",
        "from tensorflow import losses, optimizers\n",
        "from tensorflow.keras import Input, Model, models, layers, metrics\n",
        "from jarvis.train import datasets, custom\n",
        "from jarvis.train.client import Client\n",
        "from jarvis.utils.general import overload, tools as jtools\n",
        "from jarvis.utils.display import imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKO3WtHsg_GJ",
        "colab_type": "text"
      },
      "source": [
        "# Data\n",
        "\n",
        "The data used in this tutorial will consist of (frontal projection) chest radiographs from the RSNA / Kaggle pneumonia challenge (https://www.kaggle.com/c/rsna-pneumonia-detection-challenge). The chest radiograph is the standard screening exam of choice to identify and trend changes in lung disease including infection (pneumonia). \n",
        "\n",
        "The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/xr_pna`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-FvmH7fg_GK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfe40547-d486-431c-e5c4-51891886889e"
      },
      "source": [
        "# --- Download dataset\n",
        "datasets.download(name='xr/pna')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2020-05-25 17:15:14 ] [====================] 100.000% : Extracting archive (0065397 / 0065397) "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'code': '/data/raw/xr_pna', 'data': '/data/raw/xr_pna'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxg8MxbLg_GM",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "In order to create a high sensitivity classifier for pnuemonia, the following stratgies should be implemented in this assigment:\n",
        "\n",
        "* stratified sampling\n",
        "* pixel-level class weights\n",
        "* pixel-level masked loss\n",
        "\n",
        "As described in the tutorial, care must be taken to balance both the effects of using class weights to optimize for maximum sensitivity while preserving a minimum overall classifier performance as assessed via Dice score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4aBMyi4g_GN",
        "colab_type": "text"
      },
      "source": [
        "### Overload the `Client` object\n",
        "\n",
        "*Hint*: Ensure to customize the `arrays['xs']['msk']` object to reflect both class weights and masked values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqm3T0Lig_GN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@overload(Client)\n",
        "def preprocess(self, arrays, **kwargs):\n",
        "    \"\"\"\n",
        "    Method to create a custom msk array for class weights and/or masks\n",
        "    \n",
        "    \"\"\"\n",
        "    # --- Create msk\n",
        "    msk = np.zeros(arrays['xs']['dat'].shape)\n",
        "\n",
        "    lng = arrays['xs']['msk'] > 0\n",
        "    pna = arrays['ys']['pna'] > 0\n",
        "\n",
        "    msk[lng] = 1\n",
        "    msk[pna] = 5\n",
        "\n",
        "    arrays['xs']['msk'] = msk\n",
        "    \n",
        "    return arrays"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uvhYMeeg_GR",
        "colab_type": "text"
      },
      "source": [
        "### Create `Client` object\n",
        "\n",
        "After manually overloading the `Client` object, manually create a new client object.\n",
        "\n",
        "*Hint*: Ensure to use stratified sampling when initializing the client object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYYQwDtyg_GS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Find client yml file\n",
        "yml = '{}/data/ymls/client-seg.yml'.format(jtools.get_paths('xr/pna')['code'])\n",
        "\n",
        "# --- Configs dict\n",
        "configs = {\n",
        "    'batch': {'size': 8},\n",
        "    'sampling': {\n",
        "        'cohort-neg': 0.5,\n",
        "        'cohort-pna': 0.5}}\n",
        "\n",
        "# --- Manually create Client\n",
        "client = Client(yml, configs=configs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2lDN3F0g_GV",
        "colab_type": "text"
      },
      "source": [
        "### Create inputs and generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36pbgVY0g_GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Manually create generators\n",
        "gen_train, gen_valid = client.create_generators()\n",
        "\n",
        "# --- Create inputs\n",
        "inputs = client.get_inputs(Input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYgrKjyhg_GZ",
        "colab_type": "text"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtaM98aSg_Ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Define kwargs dictionary\n",
        "kwargs = {\n",
        "    'kernel_size': (1, 3, 3),\n",
        "    'padding': 'same'}\n",
        "\n",
        "# --- Define lambda functions\n",
        "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.LeakyReLU()(x)\n",
        "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
        "\n",
        "# --- Define stride-1, stride-2 blocks\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))\n",
        "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=(1, 2, 2))))\n",
        "\n",
        "# --- Define contracting layers\n",
        "l1 = conv1(8, inputs['dat'])\n",
        "l2 = conv1(16, conv2(16, l1))\n",
        "l3 = conv1(32, conv2(32, l2))\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "l5 = conv1(64, conv2(64, l4))\n",
        "l6 = conv1(80, conv2(80, l5))\n",
        "\n",
        "# --- Define expanding layers\n",
        "l7  = tran2(64, l6)\n",
        "l8  = tran2(48, conv1(64, l7  + l5))\n",
        "l9  = tran2(32, conv1(48, l8  + l4))\n",
        "l10 = tran2(16, conv1(32, l9  + l3))\n",
        "l11 = tran2(8,  conv1(16, l10 + l2))\n",
        "l12 = conv1(8,  conv1(8,  l11 + l1))\n",
        "\n",
        "# --- Create logits\n",
        "logits = {}\n",
        "logits['pna'] = layers.Conv3D(filters=2, name='pna', **kwargs)(l12)\n",
        "\n",
        "# --- Create model\n",
        "model = Model(inputs=inputs, outputs=logits) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbrb-roSg_Gc",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model\n",
        "\n",
        "*Hint*: Ensure that custom loss functions are used as described in the tutorial to properly adjust the loss function for weights and masks. In addition it may be useful to track metrics such as Dice score and sensitivity to gauge real time performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3vuUcbBg_Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Create custom weighted loss\n",
        "loss = {'pna': custom.sce(inputs['msk'])}\n",
        "\n",
        "# --- Create metrics\n",
        "metrics = custom.dsc(weights=inputs['msk'])\n",
        "metrics += [custom.softmax_ce_sens(weights=inputs['msk'])]\n",
        "metrics = {'pna': metrics}\n",
        "\n",
        "# --- Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    experimental_run_tf_function=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9MgKNGag_Gf",
        "colab_type": "text"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "Use the following cell block to train your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrQvilcrg_Gf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c877781-acec-4450-adf5-5bea7ccc323b"
      },
      "source": [
        "# --- Train model\n",
        "model.fit(\n",
        "    x=gen_train, \n",
        "    steps_per_epoch=50, \n",
        "    epochs=120,\n",
        "    validation_data=gen_valid,\n",
        "    validation_steps=50,\n",
        "    validation_freq=4,\n",
        "    use_multiprocessing=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 24s 478ms/step - loss: 0.2811 - dsc_1: 0.3135 - softmax_ce_sens: 0.5070\n",
            "Epoch 2/120\n",
            "50/50 [==============================] - 10s 198ms/step - loss: 0.2312 - dsc_1: 0.5311 - softmax_ce_sens: 0.7874\n",
            "Epoch 3/120\n",
            "50/50 [==============================] - 10s 198ms/step - loss: 0.2004 - dsc_1: 0.5137 - softmax_ce_sens: 0.7547\n",
            "Epoch 4/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2041 - dsc_1: 0.5276 - softmax_ce_sens: 0.8147WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.2864 - dsc_1: 0.3287 - softmax_ce_sens: 0.9340\n",
            "50/50 [==============================] - 19s 375ms/step - loss: 0.2021 - dsc_1: 0.5318 - softmax_ce_sens: 0.8172 - val_loss: 0.2864 - val_dsc_1: 0.3287 - val_softmax_ce_sens: 0.9340\n",
            "Epoch 5/120\n",
            "50/50 [==============================] - 10s 205ms/step - loss: 0.1844 - dsc_1: 0.5793 - softmax_ce_sens: 0.8281\n",
            "Epoch 6/120\n",
            "50/50 [==============================] - 10s 197ms/step - loss: 0.1775 - dsc_1: 0.6035 - softmax_ce_sens: 0.8713\n",
            "Epoch 7/120\n",
            "50/50 [==============================] - 10s 198ms/step - loss: 0.1730 - dsc_1: 0.6294 - softmax_ce_sens: 0.8736\n",
            "Epoch 8/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1881 - dsc_1: 0.5574 - softmax_ce_sens: 0.8422WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 154ms/step - loss: 0.1722 - dsc_1: 0.5201 - softmax_ce_sens: 0.8551\n",
            "50/50 [==============================] - 18s 354ms/step - loss: 0.1868 - dsc_1: 0.5610 - softmax_ce_sens: 0.8443 - val_loss: 0.1722 - val_dsc_1: 0.5201 - val_softmax_ce_sens: 0.8551\n",
            "Epoch 9/120\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 0.1714 - dsc_1: 0.5636 - softmax_ce_sens: 0.8227\n",
            "Epoch 10/120\n",
            "50/50 [==============================] - 10s 200ms/step - loss: 0.1688 - dsc_1: 0.5862 - softmax_ce_sens: 0.8290\n",
            "Epoch 11/120\n",
            "50/50 [==============================] - 10s 195ms/step - loss: 0.1652 - dsc_1: 0.5937 - softmax_ce_sens: 0.8625\n",
            "Epoch 12/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1710 - dsc_1: 0.6123 - softmax_ce_sens: 0.8610WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 156ms/step - loss: 0.1518 - dsc_1: 0.5558 - softmax_ce_sens: 0.8533\n",
            "50/50 [==============================] - 18s 356ms/step - loss: 0.1699 - dsc_1: 0.6089 - softmax_ce_sens: 0.8636 - val_loss: 0.1518 - val_dsc_1: 0.5558 - val_softmax_ce_sens: 0.8533\n",
            "Epoch 13/120\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1720 - dsc_1: 0.6135 - softmax_ce_sens: 0.8910\n",
            "Epoch 14/120\n",
            "50/50 [==============================] - 10s 197ms/step - loss: 0.1663 - dsc_1: 0.5770 - softmax_ce_sens: 0.8623\n",
            "Epoch 15/120\n",
            "50/50 [==============================] - 10s 199ms/step - loss: 0.1692 - dsc_1: 0.5973 - softmax_ce_sens: 0.8505\n",
            "Epoch 16/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1744 - dsc_1: 0.6193 - softmax_ce_sens: 0.8695WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 154ms/step - loss: 0.1529 - dsc_1: 0.5716 - softmax_ce_sens: 0.8477\n",
            "50/50 [==============================] - 18s 352ms/step - loss: 0.1739 - dsc_1: 0.6157 - softmax_ce_sens: 0.8721 - val_loss: 0.1529 - val_dsc_1: 0.5716 - val_softmax_ce_sens: 0.8477\n",
            "Epoch 17/120\n",
            "50/50 [==============================] - 10s 208ms/step - loss: 0.1409 - dsc_1: 0.5938 - softmax_ce_sens: 0.8700\n",
            "Epoch 18/120\n",
            "50/50 [==============================] - 10s 195ms/step - loss: 0.1548 - dsc_1: 0.5967 - softmax_ce_sens: 0.8387\n",
            "Epoch 19/120\n",
            "50/50 [==============================] - 10s 198ms/step - loss: 0.1637 - dsc_1: 0.5959 - softmax_ce_sens: 0.8876\n",
            "Epoch 20/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1679 - dsc_1: 0.6072 - softmax_ce_sens: 0.8812WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 157ms/step - loss: 0.1477 - dsc_1: 0.5617 - softmax_ce_sens: 0.8747\n",
            "50/50 [==============================] - 18s 356ms/step - loss: 0.1677 - dsc_1: 0.6091 - softmax_ce_sens: 0.8819 - val_loss: 0.1477 - val_dsc_1: 0.5617 - val_softmax_ce_sens: 0.8747\n",
            "Epoch 21/120\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 0.1726 - dsc_1: 0.5808 - softmax_ce_sens: 0.8698\n",
            "Epoch 22/120\n",
            "50/50 [==============================] - 10s 197ms/step - loss: 0.1446 - dsc_1: 0.6318 - softmax_ce_sens: 0.8868\n",
            "Epoch 23/120\n",
            "50/50 [==============================] - 10s 197ms/step - loss: 0.1470 - dsc_1: 0.6426 - softmax_ce_sens: 0.8723\n",
            "Epoch 24/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1494 - dsc_1: 0.6106 - softmax_ce_sens: 0.8557WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 154ms/step - loss: 0.1505 - dsc_1: 0.6187 - softmax_ce_sens: 0.8048\n",
            "50/50 [==============================] - 18s 351ms/step - loss: 0.1499 - dsc_1: 0.6123 - softmax_ce_sens: 0.8558 - val_loss: 0.1505 - val_dsc_1: 0.6187 - val_softmax_ce_sens: 0.8048\n",
            "Epoch 25/120\n",
            "50/50 [==============================] - 10s 205ms/step - loss: 0.1624 - dsc_1: 0.6080 - softmax_ce_sens: 0.8826\n",
            "Epoch 26/120\n",
            "50/50 [==============================] - 10s 194ms/step - loss: 0.1545 - dsc_1: 0.6179 - softmax_ce_sens: 0.8932\n",
            "Epoch 27/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1564 - dsc_1: 0.6461 - softmax_ce_sens: 0.8693\n",
            "Epoch 28/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1576 - dsc_1: 0.5796 - softmax_ce_sens: 0.8900WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 153ms/step - loss: 0.1372 - dsc_1: 0.6164 - softmax_ce_sens: 0.8207\n",
            "50/50 [==============================] - 17s 345ms/step - loss: 0.1571 - dsc_1: 0.5820 - softmax_ce_sens: 0.8882 - val_loss: 0.1372 - val_dsc_1: 0.6164 - val_softmax_ce_sens: 0.8207\n",
            "Epoch 29/120\n",
            "50/50 [==============================] - 10s 202ms/step - loss: 0.1365 - dsc_1: 0.6406 - softmax_ce_sens: 0.8960\n",
            "Epoch 30/120\n",
            "50/50 [==============================] - 10s 193ms/step - loss: 0.1506 - dsc_1: 0.6045 - softmax_ce_sens: 0.8764\n",
            "Epoch 31/120\n",
            "50/50 [==============================] - 10s 194ms/step - loss: 0.1529 - dsc_1: 0.6036 - softmax_ce_sens: 0.8979\n",
            "Epoch 32/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1376 - dsc_1: 0.6434 - softmax_ce_sens: 0.8988WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 156ms/step - loss: 0.1340 - dsc_1: 0.5983 - softmax_ce_sens: 0.8753\n",
            "50/50 [==============================] - 18s 353ms/step - loss: 0.1367 - dsc_1: 0.6408 - softmax_ce_sens: 0.9004 - val_loss: 0.1340 - val_dsc_1: 0.5983 - val_softmax_ce_sens: 0.8753\n",
            "Epoch 33/120\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 0.1428 - dsc_1: 0.6364 - softmax_ce_sens: 0.8935\n",
            "Epoch 34/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1545 - dsc_1: 0.6227 - softmax_ce_sens: 0.9026\n",
            "Epoch 35/120\n",
            "50/50 [==============================] - 10s 192ms/step - loss: 0.1381 - dsc_1: 0.6012 - softmax_ce_sens: 0.8551\n",
            "Epoch 36/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1325 - dsc_1: 0.6401 - softmax_ce_sens: 0.8830WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 155ms/step - loss: 0.1458 - dsc_1: 0.6184 - softmax_ce_sens: 0.7840\n",
            "50/50 [==============================] - 17s 346ms/step - loss: 0.1307 - dsc_1: 0.6273 - softmax_ce_sens: 0.8653 - val_loss: 0.1458 - val_dsc_1: 0.6184 - val_softmax_ce_sens: 0.7840\n",
            "Epoch 37/120\n",
            "50/50 [==============================] - 10s 206ms/step - loss: 0.1417 - dsc_1: 0.6713 - softmax_ce_sens: 0.9002\n",
            "Epoch 38/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1500 - dsc_1: 0.6232 - softmax_ce_sens: 0.9057\n",
            "Epoch 39/120\n",
            "50/50 [==============================] - 9s 190ms/step - loss: 0.1582 - dsc_1: 0.6036 - softmax_ce_sens: 0.8991\n",
            "Epoch 40/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1591 - dsc_1: 0.6248 - softmax_ce_sens: 0.8889WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.1326 - dsc_1: 0.6291 - softmax_ce_sens: 0.8309\n",
            "50/50 [==============================] - 17s 344ms/step - loss: 0.1591 - dsc_1: 0.6244 - softmax_ce_sens: 0.8887 - val_loss: 0.1326 - val_dsc_1: 0.6291 - val_softmax_ce_sens: 0.8309\n",
            "Epoch 41/120\n",
            "50/50 [==============================] - 10s 203ms/step - loss: 0.1495 - dsc_1: 0.6187 - softmax_ce_sens: 0.8978\n",
            "Epoch 42/120\n",
            "50/50 [==============================] - 10s 192ms/step - loss: 0.1627 - dsc_1: 0.6228 - softmax_ce_sens: 0.9019\n",
            "Epoch 43/120\n",
            "50/50 [==============================] - 10s 192ms/step - loss: 0.1591 - dsc_1: 0.6429 - softmax_ce_sens: 0.8808\n",
            "Epoch 44/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1507 - dsc_1: 0.6118 - softmax_ce_sens: 0.8913WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.1433 - dsc_1: 0.6270 - softmax_ce_sens: 0.7979\n",
            "50/50 [==============================] - 17s 343ms/step - loss: 0.1527 - dsc_1: 0.6145 - softmax_ce_sens: 0.8897 - val_loss: 0.1433 - val_dsc_1: 0.6270 - val_softmax_ce_sens: 0.7979\n",
            "Epoch 45/120\n",
            "50/50 [==============================] - 10s 201ms/step - loss: 0.1612 - dsc_1: 0.6109 - softmax_ce_sens: 0.8855\n",
            "Epoch 46/120\n",
            "50/50 [==============================] - 9s 188ms/step - loss: 0.1466 - dsc_1: 0.6401 - softmax_ce_sens: 0.8994\n",
            "Epoch 47/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1409 - dsc_1: 0.6591 - softmax_ce_sens: 0.8934\n",
            "Epoch 48/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1407 - dsc_1: 0.6169 - softmax_ce_sens: 0.8794WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 155ms/step - loss: 0.1304 - dsc_1: 0.6202 - softmax_ce_sens: 0.8582\n",
            "50/50 [==============================] - 17s 347ms/step - loss: 0.1398 - dsc_1: 0.6122 - softmax_ce_sens: 0.8809 - val_loss: 0.1304 - val_dsc_1: 0.6202 - val_softmax_ce_sens: 0.8582\n",
            "Epoch 49/120\n",
            "50/50 [==============================] - 10s 205ms/step - loss: 0.1355 - dsc_1: 0.6724 - softmax_ce_sens: 0.9272\n",
            "Epoch 50/120\n",
            "50/50 [==============================] - 10s 192ms/step - loss: 0.1398 - dsc_1: 0.6402 - softmax_ce_sens: 0.8973\n",
            "Epoch 51/120\n",
            "50/50 [==============================] - 10s 193ms/step - loss: 0.1389 - dsc_1: 0.6622 - softmax_ce_sens: 0.9137\n",
            "Epoch 52/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1305 - dsc_1: 0.6373 - softmax_ce_sens: 0.8833WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 154ms/step - loss: 0.1255 - dsc_1: 0.6206 - softmax_ce_sens: 0.8679\n",
            "50/50 [==============================] - 17s 347ms/step - loss: 0.1301 - dsc_1: 0.6347 - softmax_ce_sens: 0.8852 - val_loss: 0.1255 - val_dsc_1: 0.6206 - val_softmax_ce_sens: 0.8679\n",
            "Epoch 53/120\n",
            "50/50 [==============================] - 10s 202ms/step - loss: 0.1295 - dsc_1: 0.6582 - softmax_ce_sens: 0.9180\n",
            "Epoch 54/120\n",
            "50/50 [==============================] - 10s 190ms/step - loss: 0.1447 - dsc_1: 0.6408 - softmax_ce_sens: 0.8858\n",
            "Epoch 55/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1336 - dsc_1: 0.6527 - softmax_ce_sens: 0.8983\n",
            "Epoch 56/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1450 - dsc_1: 0.6137 - softmax_ce_sens: 0.8885WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.1242 - dsc_1: 0.6362 - softmax_ce_sens: 0.8579\n",
            "50/50 [==============================] - 17s 345ms/step - loss: 0.1449 - dsc_1: 0.6140 - softmax_ce_sens: 0.8898 - val_loss: 0.1242 - val_dsc_1: 0.6362 - val_softmax_ce_sens: 0.8579\n",
            "Epoch 57/120\n",
            "50/50 [==============================] - 10s 202ms/step - loss: 0.1466 - dsc_1: 0.6029 - softmax_ce_sens: 0.8734\n",
            "Epoch 58/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1276 - dsc_1: 0.6290 - softmax_ce_sens: 0.8722\n",
            "Epoch 59/120\n",
            "50/50 [==============================] - 10s 194ms/step - loss: 0.1332 - dsc_1: 0.6433 - softmax_ce_sens: 0.8763\n",
            "Epoch 60/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1376 - dsc_1: 0.6090 - softmax_ce_sens: 0.8954WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.1329 - dsc_1: 0.5915 - softmax_ce_sens: 0.8625\n",
            "50/50 [==============================] - 17s 344ms/step - loss: 0.1393 - dsc_1: 0.6056 - softmax_ce_sens: 0.8916 - val_loss: 0.1329 - val_dsc_1: 0.5915 - val_softmax_ce_sens: 0.8625\n",
            "Epoch 61/120\n",
            "50/50 [==============================] - 10s 205ms/step - loss: 0.1362 - dsc_1: 0.6462 - softmax_ce_sens: 0.9068\n",
            "Epoch 62/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1507 - dsc_1: 0.6192 - softmax_ce_sens: 0.9062\n",
            "Epoch 63/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1281 - dsc_1: 0.6270 - softmax_ce_sens: 0.9067\n",
            "Epoch 64/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1325 - dsc_1: 0.6202 - softmax_ce_sens: 0.8920WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 153ms/step - loss: 0.1364 - dsc_1: 0.5933 - softmax_ce_sens: 0.8537\n",
            "50/50 [==============================] - 17s 343ms/step - loss: 0.1314 - dsc_1: 0.6181 - softmax_ce_sens: 0.8908 - val_loss: 0.1364 - val_dsc_1: 0.5933 - val_softmax_ce_sens: 0.8537\n",
            "Epoch 65/120\n",
            "50/50 [==============================] - 10s 202ms/step - loss: 0.1429 - dsc_1: 0.6491 - softmax_ce_sens: 0.9101\n",
            "Epoch 66/120\n",
            "50/50 [==============================] - 9s 189ms/step - loss: 0.1390 - dsc_1: 0.6292 - softmax_ce_sens: 0.9020\n",
            "Epoch 67/120\n",
            "50/50 [==============================] - 9s 190ms/step - loss: 0.1307 - dsc_1: 0.6509 - softmax_ce_sens: 0.9004\n",
            "Epoch 68/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1290 - dsc_1: 0.6607 - softmax_ce_sens: 0.9123WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 153ms/step - loss: 0.1250 - dsc_1: 0.6130 - softmax_ce_sens: 0.8944\n",
            "50/50 [==============================] - 17s 344ms/step - loss: 0.1298 - dsc_1: 0.6638 - softmax_ce_sens: 0.9116 - val_loss: 0.1250 - val_dsc_1: 0.6130 - val_softmax_ce_sens: 0.8944\n",
            "Epoch 69/120\n",
            "50/50 [==============================] - 10s 203ms/step - loss: 0.1270 - dsc_1: 0.6293 - softmax_ce_sens: 0.8817\n",
            "Epoch 70/120\n",
            "50/50 [==============================] - 10s 192ms/step - loss: 0.1289 - dsc_1: 0.6648 - softmax_ce_sens: 0.9031\n",
            "Epoch 71/120\n",
            "50/50 [==============================] - 10s 190ms/step - loss: 0.1318 - dsc_1: 0.6584 - softmax_ce_sens: 0.9277\n",
            "Epoch 72/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1386 - dsc_1: 0.6688 - softmax_ce_sens: 0.9184WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 153ms/step - loss: 0.1243 - dsc_1: 0.6109 - softmax_ce_sens: 0.8764\n",
            "50/50 [==============================] - 17s 343ms/step - loss: 0.1378 - dsc_1: 0.6678 - softmax_ce_sens: 0.9195 - val_loss: 0.1243 - val_dsc_1: 0.6109 - val_softmax_ce_sens: 0.8764\n",
            "Epoch 73/120\n",
            "50/50 [==============================] - 10s 200ms/step - loss: 0.1184 - dsc_1: 0.6562 - softmax_ce_sens: 0.9317\n",
            "Epoch 74/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1308 - dsc_1: 0.6650 - softmax_ce_sens: 0.9123\n",
            "Epoch 75/120\n",
            "50/50 [==============================] - 10s 190ms/step - loss: 0.1311 - dsc_1: 0.6292 - softmax_ce_sens: 0.8800\n",
            "Epoch 76/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1224 - dsc_1: 0.6524 - softmax_ce_sens: 0.9030WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 154ms/step - loss: 0.1263 - dsc_1: 0.6417 - softmax_ce_sens: 0.8395\n",
            "50/50 [==============================] - 17s 346ms/step - loss: 0.1207 - dsc_1: 0.6471 - softmax_ce_sens: 0.9049 - val_loss: 0.1263 - val_dsc_1: 0.6417 - val_softmax_ce_sens: 0.8395\n",
            "Epoch 77/120\n",
            "50/50 [==============================] - 10s 205ms/step - loss: 0.1378 - dsc_1: 0.6403 - softmax_ce_sens: 0.8746\n",
            "Epoch 78/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1336 - dsc_1: 0.6453 - softmax_ce_sens: 0.9153\n",
            "Epoch 79/120\n",
            "50/50 [==============================] - 10s 194ms/step - loss: 0.1380 - dsc_1: 0.6146 - softmax_ce_sens: 0.9126\n",
            "Epoch 80/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1170 - dsc_1: 0.6808 - softmax_ce_sens: 0.9048WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 152ms/step - loss: 0.1400 - dsc_1: 0.5664 - softmax_ce_sens: 0.9117\n",
            "50/50 [==============================] - 17s 343ms/step - loss: 0.1171 - dsc_1: 0.6787 - softmax_ce_sens: 0.9067 - val_loss: 0.1400 - val_dsc_1: 0.5664 - val_softmax_ce_sens: 0.9117\n",
            "Epoch 81/120\n",
            "50/50 [==============================] - 10s 200ms/step - loss: 0.1355 - dsc_1: 0.6863 - softmax_ce_sens: 0.9244\n",
            "Epoch 82/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1463 - dsc_1: 0.6542 - softmax_ce_sens: 0.9148\n",
            "Epoch 83/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1355 - dsc_1: 0.6231 - softmax_ce_sens: 0.9039\n",
            "Epoch 84/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1276 - dsc_1: 0.6201 - softmax_ce_sens: 0.9062WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 151ms/step - loss: 0.1269 - dsc_1: 0.5927 - softmax_ce_sens: 0.9067\n",
            "50/50 [==============================] - 17s 343ms/step - loss: 0.1270 - dsc_1: 0.6218 - softmax_ce_sens: 0.9076 - val_loss: 0.1269 - val_dsc_1: 0.5927 - val_softmax_ce_sens: 0.9067\n",
            "Epoch 85/120\n",
            "50/50 [==============================] - 10s 204ms/step - loss: 0.1425 - dsc_1: 0.6297 - softmax_ce_sens: 0.8941\n",
            "Epoch 86/120\n",
            "50/50 [==============================] - 10s 193ms/step - loss: 0.1311 - dsc_1: 0.6555 - softmax_ce_sens: 0.9181\n",
            "Epoch 87/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1293 - dsc_1: 0.6576 - softmax_ce_sens: 0.8781\n",
            "Epoch 88/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1307 - dsc_1: 0.6736 - softmax_ce_sens: 0.9386WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 155ms/step - loss: 0.1206 - dsc_1: 0.6359 - softmax_ce_sens: 0.8660\n",
            "50/50 [==============================] - 17s 346ms/step - loss: 0.1307 - dsc_1: 0.6724 - softmax_ce_sens: 0.9384 - val_loss: 0.1206 - val_dsc_1: 0.6359 - val_softmax_ce_sens: 0.8660\n",
            "Epoch 89/120\n",
            "50/50 [==============================] - 10s 201ms/step - loss: 0.1100 - dsc_1: 0.6431 - softmax_ce_sens: 0.9139\n",
            "Epoch 90/120\n",
            "50/50 [==============================] - 10s 193ms/step - loss: 0.1316 - dsc_1: 0.6465 - softmax_ce_sens: 0.8957\n",
            "Epoch 91/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1330 - dsc_1: 0.6358 - softmax_ce_sens: 0.9230\n",
            "Epoch 92/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1426 - dsc_1: 0.6602 - softmax_ce_sens: 0.9158WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 154ms/step - loss: 0.1265 - dsc_1: 0.5938 - softmax_ce_sens: 0.9108\n",
            "50/50 [==============================] - 17s 347ms/step - loss: 0.1434 - dsc_1: 0.6611 - softmax_ce_sens: 0.9134 - val_loss: 0.1265 - val_dsc_1: 0.5938 - val_softmax_ce_sens: 0.9108\n",
            "Epoch 93/120\n",
            "50/50 [==============================] - 10s 203ms/step - loss: 0.1132 - dsc_1: 0.6514 - softmax_ce_sens: 0.9092\n",
            "Epoch 94/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1656 - dsc_1: 0.6215 - softmax_ce_sens: 0.9163\n",
            "Epoch 95/120\n",
            "50/50 [==============================] - 10s 192ms/step - loss: 0.1174 - dsc_1: 0.6654 - softmax_ce_sens: 0.9216\n",
            "Epoch 96/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1218 - dsc_1: 0.6672 - softmax_ce_sens: 0.9354WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 159ms/step - loss: 0.1276 - dsc_1: 0.6468 - softmax_ce_sens: 0.8409\n",
            "50/50 [==============================] - 18s 351ms/step - loss: 0.1232 - dsc_1: 0.6667 - softmax_ce_sens: 0.9321 - val_loss: 0.1276 - val_dsc_1: 0.6468 - val_softmax_ce_sens: 0.8409\n",
            "Epoch 97/120\n",
            "50/50 [==============================] - 10s 204ms/step - loss: 0.1521 - dsc_1: 0.6509 - softmax_ce_sens: 0.9116\n",
            "Epoch 98/120\n",
            "50/50 [==============================] - 10s 192ms/step - loss: 0.1358 - dsc_1: 0.6337 - softmax_ce_sens: 0.9148\n",
            "Epoch 99/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1275 - dsc_1: 0.6712 - softmax_ce_sens: 0.9326\n",
            "Epoch 100/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1226 - dsc_1: 0.6449 - softmax_ce_sens: 0.9018WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 155ms/step - loss: 0.1541 - dsc_1: 0.6425 - softmax_ce_sens: 0.8006\n",
            "50/50 [==============================] - 17s 347ms/step - loss: 0.1221 - dsc_1: 0.6437 - softmax_ce_sens: 0.9033 - val_loss: 0.1541 - val_dsc_1: 0.6425 - val_softmax_ce_sens: 0.8006\n",
            "Epoch 101/120\n",
            "50/50 [==============================] - 10s 205ms/step - loss: 0.1353 - dsc_1: 0.6677 - softmax_ce_sens: 0.9134\n",
            "Epoch 102/120\n",
            "50/50 [==============================] - 10s 192ms/step - loss: 0.1290 - dsc_1: 0.6605 - softmax_ce_sens: 0.9031\n",
            "Epoch 103/120\n",
            "50/50 [==============================] - 10s 193ms/step - loss: 0.1187 - dsc_1: 0.6729 - softmax_ce_sens: 0.9237\n",
            "Epoch 104/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1342 - dsc_1: 0.6405 - softmax_ce_sens: 0.9152WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 157ms/step - loss: 0.1244 - dsc_1: 0.6563 - softmax_ce_sens: 0.8506\n",
            "50/50 [==============================] - 17s 350ms/step - loss: 0.1338 - dsc_1: 0.6397 - softmax_ce_sens: 0.9157 - val_loss: 0.1244 - val_dsc_1: 0.6563 - val_softmax_ce_sens: 0.8506\n",
            "Epoch 105/120\n",
            "50/50 [==============================] - 10s 204ms/step - loss: 0.1291 - dsc_1: 0.6454 - softmax_ce_sens: 0.8952\n",
            "Epoch 106/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1178 - dsc_1: 0.6516 - softmax_ce_sens: 0.9143\n",
            "Epoch 107/120\n",
            "50/50 [==============================] - 10s 192ms/step - loss: 0.1351 - dsc_1: 0.6596 - softmax_ce_sens: 0.8992\n",
            "Epoch 108/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1386 - dsc_1: 0.6900 - softmax_ce_sens: 0.9234WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 154ms/step - loss: 0.1249 - dsc_1: 0.6548 - softmax_ce_sens: 0.8173\n",
            "50/50 [==============================] - 17s 347ms/step - loss: 0.1384 - dsc_1: 0.6898 - softmax_ce_sens: 0.9241 - val_loss: 0.1249 - val_dsc_1: 0.6548 - val_softmax_ce_sens: 0.8173\n",
            "Epoch 109/120\n",
            "50/50 [==============================] - 10s 202ms/step - loss: 0.1246 - dsc_1: 0.6783 - softmax_ce_sens: 0.9347\n",
            "Epoch 110/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1203 - dsc_1: 0.6362 - softmax_ce_sens: 0.8613\n",
            "Epoch 111/120\n",
            "50/50 [==============================] - 9s 190ms/step - loss: 0.1330 - dsc_1: 0.6763 - softmax_ce_sens: 0.9260\n",
            "Epoch 112/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1300 - dsc_1: 0.6859 - softmax_ce_sens: 0.9259WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 158ms/step - loss: 0.1280 - dsc_1: 0.6405 - softmax_ce_sens: 0.8359\n",
            "50/50 [==============================] - 17s 349ms/step - loss: 0.1301 - dsc_1: 0.6833 - softmax_ce_sens: 0.9245 - val_loss: 0.1280 - val_dsc_1: 0.6405 - val_softmax_ce_sens: 0.8359\n",
            "Epoch 113/120\n",
            "50/50 [==============================] - 10s 202ms/step - loss: 0.1169 - dsc_1: 0.6415 - softmax_ce_sens: 0.8934\n",
            "Epoch 114/120\n",
            "50/50 [==============================] - 10s 191ms/step - loss: 0.1266 - dsc_1: 0.6993 - softmax_ce_sens: 0.9242\n",
            "Epoch 115/120\n",
            "50/50 [==============================] - 10s 192ms/step - loss: 0.1173 - dsc_1: 0.6591 - softmax_ce_sens: 0.8874\n",
            "Epoch 116/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1299 - dsc_1: 0.6729 - softmax_ce_sens: 0.9302WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 154ms/step - loss: 0.1260 - dsc_1: 0.6014 - softmax_ce_sens: 0.8712\n",
            "50/50 [==============================] - 17s 347ms/step - loss: 0.1299 - dsc_1: 0.6716 - softmax_ce_sens: 0.9314 - val_loss: 0.1260 - val_dsc_1: 0.6014 - val_softmax_ce_sens: 0.8712\n",
            "Epoch 117/120\n",
            "50/50 [==============================] - 10s 203ms/step - loss: 0.1391 - dsc_1: 0.6562 - softmax_ce_sens: 0.9222\n",
            "Epoch 118/120\n",
            "50/50 [==============================] - 10s 190ms/step - loss: 0.1258 - dsc_1: 0.6827 - softmax_ce_sens: 0.9135\n",
            "Epoch 119/120\n",
            "50/50 [==============================] - 10s 190ms/step - loss: 0.1184 - dsc_1: 0.6662 - softmax_ce_sens: 0.9235\n",
            "Epoch 120/120\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1284 - dsc_1: 0.6264 - softmax_ce_sens: 0.9045WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "Epoch 1/120\n",
            "50/50 [==============================] - 8s 155ms/step - loss: 0.1355 - dsc_1: 0.6355 - softmax_ce_sens: 0.8312\n",
            "50/50 [==============================] - 17s 348ms/step - loss: 0.1279 - dsc_1: 0.6286 - softmax_ce_sens: 0.9046 - val_loss: 0.1355 - val_dsc_1: 0.6355 - val_softmax_ce_sens: 0.8312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcafc53f208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmSMYuEcg_Gi",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Based on the tutorial discussion, use the following cells to calculate model performance. The following metrics should be calculated:\n",
        "\n",
        "* pixel-wise sensitivity\n",
        "* Dice score coefficient\n",
        "\n",
        "### Performance\n",
        "\n",
        "The following minimum performance metrics must be met for full credit:\n",
        "\n",
        "* pixel-wise sensitivity: >0.75\n",
        "* Dice score coefficient: >0.50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqa5thkqg_Gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR1UWTSWw6xB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_sens(pred, true, epsilon=1):\n",
        "    \"\"\"\n",
        "    Method to calculate sensitivity from pred and true masks\n",
        "    \n",
        "    \"\"\"\n",
        "    assert pred.shape == true.shape\n",
        "    tp = (pred == 1) & (true == 1)\n",
        "    ap = (true == 1)\n",
        "\n",
        "    return np.count_nonzero(tp) / (np.count_nonzero(ap) + epsilon)\n",
        "\n",
        "\n",
        "def calculate_dice(y_true, y_pred, c=1, epsilon=1):\n",
        "    \"\"\"\n",
        "    Method to calculate the Dice score coefficient for given class\n",
        "    \n",
        "    :params\n",
        "    \n",
        "      (np.ndarray) y_true : ground-truth label\n",
        "      (np.ndarray) y_pred : predicted logits scores\n",
        "      (int)             c : class to calculate DSC on\n",
        "    \n",
        "    \"\"\"\n",
        "    assert y_true.ndim == y_pred.ndim\n",
        "    \n",
        "    true = y_true[..., 0] == c\n",
        "    pred = np.argmax(y_pred, axis=-1) == c \n",
        "\n",
        "    A = np.count_nonzero(true & pred) * 2\n",
        "    B = np.count_nonzero(true) + np.count_nonzero(pred) + epsilon\n",
        "    \n",
        "    return A / B"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thxv19wVxqx_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "264fd44d-a2a5-4468-e3fb-ee612d8b3e9d"
      },
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True)\n",
        "\n",
        "dice_array = []\n",
        "sens_array = []\n",
        "for x, y in test_valid:\n",
        "    # --- Create prediction\n",
        "    logits = model.predict(x)\n",
        "    pred = np.argmax(logits[0], axis=-1)\n",
        "    \n",
        "    # --- Clean up pred using mask\n",
        "    pred[x['msk'][0, ..., 0] == 0] = 0\n",
        "\n",
        "    # --- Calculate Dice\n",
        "    dice = calculate_dice(y['pna'][0], logits[0])\n",
        "    dice_array.append(dice)\n",
        "    \n",
        "    \n",
        "    # --- Calculate sens\n",
        "    sens = calculate_sens(pred=pred, true=y['pna'][0, ..., 0])\n",
        "    sens_array.append(sens)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2020-05-25 18:47:15 ] [====================] 100.000% : Iterating | 002994    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JipD80ng_Gl",
        "colab_type": "text"
      },
      "source": [
        "### Results\n",
        "\n",
        "When ready, create a `*.csv` file with your compiled **validation** cohort sensitivity and Dice score statistics. There is no need to submit training performance accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3E-TQzBg_Gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dice_array = np.array(dice_array)\n",
        "sens_array = np.array(sens_array)\n",
        "\n",
        "# --- Define columns\n",
        "df = pd.DataFrame(index=np.arange(sens_array.size))\n",
        "df['dice'] = dice_array\n",
        "df['sens'] = sens_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "478MFjTtHUdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "fname = '{}/models/lesion_segmentation/gej4_results.csv'.format(MOUNT_ROOT)\n",
        "os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
        "df.to_csv(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujZMSRbjg_Gp",
        "colab_type": "text"
      },
      "source": [
        "# Submission\n",
        "\n",
        "Use the following line to save your model for submission (in Google Colab this should save your model file into your personal Google Drive):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54A-5GsRg_Gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Serialize a model\n",
        "fname = '{}/models/lesion_segmentation/gej4_final.hdf5'.format(MOUNT_ROOT)\n",
        "os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
        "model.save(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrAnrmDfg_Gs",
        "colab_type": "text"
      },
      "source": [
        "### Canvas\n",
        "\n",
        "Once you have completed this assignment, download the necessary files from Google Colab and your Google Drive. You will then need to submit the following items:\n",
        "\n",
        "* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n",
        "* final (results) spreadsheet: `[UCInetID]_results.csv`\n",
        "* final (trained) model: `[UCInetID]_model.hdf5`\n",
        "\n",
        "**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooke file would be submitted under the name `panteater_notebook.ipynb`, his spreadshhet would be submitted under the name `panteater_results.csv` and and his model file would be submitted under the name `panteater_model.hdf5`."
      ]
    }
  ]
}